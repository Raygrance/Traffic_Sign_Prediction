{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3318943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df39b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.567237609329446\n",
      "50.05648688046647\n"
     ]
    }
   ],
   "source": [
    "# calculate average size to help inform a size to resize all images to\n",
    "imagex = 0\n",
    "imagey = 0\n",
    "for i in range(1, 5489):    \n",
    "    image = Image.open(f'Data/train/img_00{i:04d}.jpg')\n",
    "    imagex += image.size[0]\n",
    "    imagey += image.size[1]\n",
    "    \n",
    "print(imagex/5488) # 50.567237609329446\n",
    "print(imagey/5488) # 50.05648688046647\n",
    "\n",
    "# scale to 50 x 50\n",
    "rescale_size = (50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ed4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 81,  70,  71],\n",
       "         [ 79,  69,  71],\n",
       "         [ 74,  65,  68],\n",
       "         ...,\n",
       "         [ 71,  61,  60],\n",
       "         [ 66,  59,  58],\n",
       "         [ 61,  57,  56]],\n",
       "\n",
       "        [[ 79,  68,  70],\n",
       "         [ 77,  67,  69],\n",
       "         [ 73,  64,  67],\n",
       "         ...,\n",
       "         [ 70,  61,  60],\n",
       "         [ 66,  60,  58],\n",
       "         [ 61,  58,  56]],\n",
       "\n",
       "        [[ 77,  66,  69],\n",
       "         [ 75,  65,  67],\n",
       "         [ 72,  63,  65],\n",
       "         ...,\n",
       "         [ 68,  61,  59],\n",
       "         [ 65,  61,  58],\n",
       "         [ 62,  60,  57]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 35,  35,  33],\n",
       "         [ 35,  35,  32],\n",
       "         [ 36,  35,  31],\n",
       "         ...,\n",
       "         [ 43,  37,  34],\n",
       "         [ 42,  37,  35],\n",
       "         [ 42,  37,  35]],\n",
       "\n",
       "        [[ 33,  32,  32],\n",
       "         [ 33,  32,  31],\n",
       "         [ 34,  33,  31],\n",
       "         ...,\n",
       "         [ 39,  34,  33],\n",
       "         [ 38,  34,  33],\n",
       "         [ 38,  34,  33]],\n",
       "\n",
       "        [[ 32,  31,  31],\n",
       "         [ 33,  31,  31],\n",
       "         [ 34,  32,  32],\n",
       "         ...,\n",
       "         [ 39,  34,  34],\n",
       "         [ 38,  34,  34],\n",
       "         [ 38,  34,  34]]],\n",
       "\n",
       "\n",
       "       [[[ 44,  34,  27],\n",
       "         [ 46,  36,  29],\n",
       "         [ 46,  36,  30],\n",
       "         ...,\n",
       "         [ 36,  35,  23],\n",
       "         [ 35,  34,  22],\n",
       "         [ 37,  35,  23]],\n",
       "\n",
       "        [[ 43,  34,  26],\n",
       "         [ 42,  36,  28],\n",
       "         [ 41,  37,  31],\n",
       "         ...,\n",
       "         [ 33,  33,  22],\n",
       "         [ 34,  33,  21],\n",
       "         [ 33,  30,  18]],\n",
       "\n",
       "        [[ 45,  36,  28],\n",
       "         [ 40,  37,  32],\n",
       "         [ 46,  49,  45],\n",
       "         ...,\n",
       "         [ 31,  32,  22],\n",
       "         [ 34,  32,  22],\n",
       "         [ 34,  29,  19]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 49,  30,  21],\n",
       "         [ 30,  24,  16],\n",
       "         [ 21,  28,  19],\n",
       "         ...,\n",
       "         [ 25,  22,  19],\n",
       "         [ 19,  20,  17],\n",
       "         [ 22,  25,  21]],\n",
       "\n",
       "        [[ 45,  33,  24],\n",
       "         [ 28,  24,  17],\n",
       "         [ 22,  25,  18],\n",
       "         ...,\n",
       "         [ 19,  19,  17],\n",
       "         [ 21,  21,  19],\n",
       "         [ 22,  23,  19]],\n",
       "\n",
       "        [[ 37,  30,  22],\n",
       "         [ 28,  25,  18],\n",
       "         [ 24,  25,  18],\n",
       "         ...,\n",
       "         [ 20,  22,  18],\n",
       "         [ 22,  22,  18],\n",
       "         [ 27,  26,  20]]],\n",
       "\n",
       "\n",
       "       [[[ 72,  94, 113],\n",
       "         [ 61,  73,  91],\n",
       "         [ 77,  81, 101],\n",
       "         ...,\n",
       "         [ 81,  88, 112],\n",
       "         [ 66,  83,  99],\n",
       "         [ 58,  65,  75]],\n",
       "\n",
       "        [[ 72,  87, 106],\n",
       "         [ 62,  73,  82],\n",
       "         [ 69,  76,  96],\n",
       "         ...,\n",
       "         [ 76,  86, 126],\n",
       "         [ 68,  80, 107],\n",
       "         [ 61,  67,  77]],\n",
       "\n",
       "        [[ 71,  79,  88],\n",
       "         [ 65,  74,  78],\n",
       "         [ 73,  84, 106],\n",
       "         ...,\n",
       "         [ 70,  83, 122],\n",
       "         [ 63,  71,  97],\n",
       "         [ 64,  69,  75]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 39,  40,  41],\n",
       "         [ 37,  39,  40],\n",
       "         [ 38,  41,  43],\n",
       "         ...,\n",
       "         [ 11,  11,  14],\n",
       "         [ 12,  11,  14],\n",
       "         [ 12,  11,  13]],\n",
       "\n",
       "        [[ 41,  42,  42],\n",
       "         [ 39,  41,  41],\n",
       "         [ 39,  42,  45],\n",
       "         ...,\n",
       "         [ 10,  10,  15],\n",
       "         [ 10,  10,  14],\n",
       "         [ 11,  10,  14]],\n",
       "\n",
       "        [[ 40,  42,  44],\n",
       "         [ 42,  44,  45],\n",
       "         [ 38,  41,  44],\n",
       "         ...,\n",
       "         [ 22,  21,  23],\n",
       "         [ 20,  20,  21],\n",
       "         [ 22,  21,  21]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 31,  33,  25],\n",
       "         [ 34,  35,  21],\n",
       "         [ 25,  45,  20],\n",
       "         ...,\n",
       "         [ 20,  20,  16],\n",
       "         [ 21,  20,  18],\n",
       "         [ 18,  17,  15]],\n",
       "\n",
       "        [[ 26,  35,  28],\n",
       "         [ 29,  36,  24],\n",
       "         [ 65,  77,  49],\n",
       "         ...,\n",
       "         [ 19,  31,  30],\n",
       "         [ 28,  23,  22],\n",
       "         [ 28,  20,  18]],\n",
       "\n",
       "        [[ 40,  46,  38],\n",
       "         [ 38,  42,  36],\n",
       "         [ 48,  53,  43],\n",
       "         ...,\n",
       "         [ 46,  55,  52],\n",
       "         [ 44,  36,  29],\n",
       "         [ 33,  22,  18]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 47,  50,  31],\n",
       "         [ 48,  50,  38],\n",
       "         [ 50,  51,  42],\n",
       "         ...,\n",
       "         [230, 143, 124],\n",
       "         [107,  75,  55],\n",
       "         [ 42,  39,  13]],\n",
       "\n",
       "        [[ 82,  65,  38],\n",
       "         [ 39,  51,  30],\n",
       "         [ 50,  65,  48],\n",
       "         ...,\n",
       "         [229, 200, 196],\n",
       "         [100,  83,  67],\n",
       "         [ 98,  83,  53]],\n",
       "\n",
       "        [[116, 107,  60],\n",
       "         [ 77,  87,  44],\n",
       "         [ 53,  63,  35],\n",
       "         ...,\n",
       "         [222, 216, 206],\n",
       "         [ 81,  76,  56],\n",
       "         [ 96,  85,  64]]],\n",
       "\n",
       "\n",
       "       [[[217, 220, 229],\n",
       "         [213, 219, 226],\n",
       "         [211, 221, 229],\n",
       "         ...,\n",
       "         [202, 207, 216],\n",
       "         [202, 208, 218],\n",
       "         [199, 207, 217]],\n",
       "\n",
       "        [[212, 218, 230],\n",
       "         [212, 219, 229],\n",
       "         [211, 220, 229],\n",
       "         ...,\n",
       "         [198, 204, 215],\n",
       "         [198, 204, 216],\n",
       "         [198, 204, 215]],\n",
       "\n",
       "        [[207, 217, 228],\n",
       "         [211, 220, 228],\n",
       "         [214, 222, 230],\n",
       "         ...,\n",
       "         [200, 207, 218],\n",
       "         [205, 211, 223],\n",
       "         [203, 208, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 20,  19,  23],\n",
       "         [ 18,  17,  22],\n",
       "         [ 20,  18,  22],\n",
       "         ...,\n",
       "         [ 30,  31,  36],\n",
       "         [ 29,  32,  41],\n",
       "         [ 29,  34,  41]],\n",
       "\n",
       "        [[ 19,  17,  21],\n",
       "         [ 19,  17,  21],\n",
       "         [ 20,  17,  21],\n",
       "         ...,\n",
       "         [ 37,  39,  41],\n",
       "         [ 41,  44,  48],\n",
       "         [ 36,  40,  43]],\n",
       "\n",
       "        [[ 17,  16,  20],\n",
       "         [ 17,  16,  20],\n",
       "         [ 18,  17,  21],\n",
       "         ...,\n",
       "         [ 57,  57,  57],\n",
       "         [ 59,  59,  59],\n",
       "         [ 43,  44,  43]]],\n",
       "\n",
       "\n",
       "       [[[ 98, 112, 136],\n",
       "         [106, 121, 155],\n",
       "         [105, 118, 163],\n",
       "         ...,\n",
       "         [ 25,  22,  23],\n",
       "         [ 26,  23,  22],\n",
       "         [ 28,  26,  27]],\n",
       "\n",
       "        [[ 82,  99, 121],\n",
       "         [ 82, 101, 123],\n",
       "         [ 90, 103, 132],\n",
       "         ...,\n",
       "         [ 25,  21,  21],\n",
       "         [ 23,  19,  18],\n",
       "         [ 20,  19,  20]],\n",
       "\n",
       "        [[ 95, 117, 127],\n",
       "         [108, 126, 146],\n",
       "         [115, 128, 148],\n",
       "         ...,\n",
       "         [ 27,  22,  22],\n",
       "         [ 27,  22,  22],\n",
       "         [ 25,  21,  20]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  8,  13,  17],\n",
       "         [  8,  13,  16],\n",
       "         [  8,  13,  16],\n",
       "         ...,\n",
       "         [ 20,  17,  15],\n",
       "         [ 18,  16,  16],\n",
       "         [ 19,  15,  16]],\n",
       "\n",
       "        [[  9,  13,  16],\n",
       "         [  9,  14,  17],\n",
       "         [  8,  13,  17],\n",
       "         ...,\n",
       "         [ 17,  15,  15],\n",
       "         [ 15,  15,  15],\n",
       "         [ 17,  15,  15]],\n",
       "\n",
       "        [[  9,  13,  16],\n",
       "         [  9,  14,  18],\n",
       "         [  9,  14,  18],\n",
       "         ...,\n",
       "         [ 16,  14,  16],\n",
       "         [ 18,  17,  16],\n",
       "         [ 19,  16,  17]]]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import image files as pixel RGB values\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "# import paths and labels\n",
    "train_metadata = pd.read_csv(\"Data/train/train_metadata.csv\", index_col=\"id\")\n",
    "train_paths = train_metadata[\"image_path\"]\n",
    "train_class = train_metadata[\"ClassId\"]\n",
    "\n",
    "for i in range(len(train_paths)):\n",
    "    try:\n",
    "        # open image\n",
    "        image = Image.open(f\"Data/train/{train_paths.iloc[i]}\")\n",
    "        # resize image to (50, 50)\n",
    "        image = image.resize(rescale_size)\n",
    "        image = np.array(image)\n",
    "        train_data.append(image)\n",
    "        train_labels.append(train_class.iloc[i])\n",
    "    except:\n",
    "        print(f\"error loading image {train_paths.iloc[i]}\")\n",
    "\n",
    "data = np.array(train_data)\n",
    "labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has shape: (5488, 50, 50, 3)\n",
      "labels have shape: (5488,)\n",
      "X_train has shape: (4390, 50, 50, 3)\n",
      "X_test has shape: (1098, 50, 50, 3)\n",
      "y_train has shape: (4390,)\n",
      "y_test has shape: (1098,)\n",
      "(4390, 43)\n"
     ]
    }
   ],
   "source": [
    "# sanity check data\n",
    "\n",
    "print(f\"data has shape: {data.shape}\")\n",
    "print(f\"labels have shape: {labels.shape}\")\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=69)\n",
    "\n",
    "print(f\"X_train has shape: {X_train.shape}\")\n",
    "print(f\"X_test has shape: {X_test.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de68bbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayzh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,389,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,059</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m51,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m8,389,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │        \u001b[38;5;34m22,059\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,833,899</span> (33.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,833,899\u001b[0m (33.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,833,899</span> (33.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,833,899\u001b[0m (33.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.15))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#M odel display\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dd5488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.0855 - loss: 14.9181 - val_accuracy: 0.4299 - val_loss: 2.1528\n",
      "Epoch 2/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.5303 - loss: 1.8151 - val_accuracy: 0.8215 - val_loss: 0.8276\n",
      "Epoch 3/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.8068 - loss: 0.6909 - val_accuracy: 0.9308 - val_loss: 0.3511\n",
      "Epoch 4/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.9052 - loss: 0.3525 - val_accuracy: 0.9353 - val_loss: 0.2423\n",
      "Epoch 5/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - accuracy: 0.9348 - loss: 0.2465 - val_accuracy: 0.9472 - val_loss: 0.2105\n",
      "Epoch 6/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.9421 - loss: 0.2191 - val_accuracy: 0.9599 - val_loss: 0.1975\n",
      "Epoch 7/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9605 - loss: 0.1597 - val_accuracy: 0.9545 - val_loss: 0.1896\n",
      "Epoch 8/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.9643 - loss: 0.1286 - val_accuracy: 0.9599 - val_loss: 0.2009\n",
      "Epoch 9/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9670 - loss: 0.1193 - val_accuracy: 0.9699 - val_loss: 0.0994\n",
      "Epoch 10/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9801 - loss: 0.0773 - val_accuracy: 0.9645 - val_loss: 0.1545\n",
      "Epoch 11/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9795 - loss: 0.0817 - val_accuracy: 0.9545 - val_loss: 0.1880\n",
      "Epoch 12/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9699 - loss: 0.1107 - val_accuracy: 0.9554 - val_loss: 0.1931\n",
      "Epoch 13/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.9764 - loss: 0.0819 - val_accuracy: 0.9736 - val_loss: 0.1090\n",
      "Epoch 14/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.9810 - loss: 0.0763 - val_accuracy: 0.9718 - val_loss: 0.0963\n",
      "Epoch 15/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.9902 - loss: 0.0338 - val_accuracy: 0.9763 - val_loss: 0.0917\n",
      "Epoch 16/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9718 - val_loss: 0.1224\n",
      "Epoch 17/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9858 - loss: 0.0544 - val_accuracy: 0.9763 - val_loss: 0.0997\n",
      "Epoch 18/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9948 - loss: 0.0202 - val_accuracy: 0.9590 - val_loss: 0.1962\n",
      "Epoch 19/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 221ms/step - accuracy: 0.9879 - loss: 0.0395 - val_accuracy: 0.9718 - val_loss: 0.1051\n",
      "Epoch 20/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.9882 - loss: 0.0423 - val_accuracy: 0.9736 - val_loss: 0.1189\n",
      "Epoch 21/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.9895 - loss: 0.0337 - val_accuracy: 0.9809 - val_loss: 0.0961\n",
      "Epoch 22/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.9919 - loss: 0.0317 - val_accuracy: 0.9772 - val_loss: 0.1048\n",
      "Epoch 23/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 206ms/step - accuracy: 0.9937 - loss: 0.0318 - val_accuracy: 0.9663 - val_loss: 0.1611\n",
      "Epoch 24/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.9839 - loss: 0.0571 - val_accuracy: 0.9772 - val_loss: 0.1171\n",
      "Epoch 25/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.9865 - loss: 0.0608 - val_accuracy: 0.9681 - val_loss: 0.1544\n",
      "Epoch 26/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.9863 - loss: 0.0645 - val_accuracy: 0.9645 - val_loss: 0.1531\n",
      "Epoch 27/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.9788 - loss: 0.0723 - val_accuracy: 0.9699 - val_loss: 0.1302\n",
      "Epoch 28/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.9867 - loss: 0.0498 - val_accuracy: 0.9727 - val_loss: 0.1547\n",
      "Epoch 29/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - accuracy: 0.9842 - loss: 0.0862 - val_accuracy: 0.9572 - val_loss: 0.2248\n",
      "Epoch 30/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - accuracy: 0.9702 - loss: 0.1077 - val_accuracy: 0.9690 - val_loss: 0.1705\n",
      "Epoch 31/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9773 - loss: 0.0973 - val_accuracy: 0.9617 - val_loss: 0.2220\n",
      "Epoch 32/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9855 - loss: 0.0831 - val_accuracy: 0.9663 - val_loss: 0.1656\n",
      "Epoch 33/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.9897 - loss: 0.0454 - val_accuracy: 0.9681 - val_loss: 0.1768\n",
      "Epoch 34/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.9898 - loss: 0.0413 - val_accuracy: 0.9754 - val_loss: 0.1315\n",
      "Epoch 35/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9954 - loss: 0.0204 - val_accuracy: 0.9727 - val_loss: 0.1466\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "with tf.device('/GPU:0'):\n",
    "    epochs = 35\n",
    "    history1 = model.fit(X_train, y_train, batch_size=128, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2353, 50, 50, 3)\n",
      "[661, 4477, 1046, 631, 6533, 2899, 1941, 5749, 588, 1333, 5826, 7493, 4306, 3429, 1191, 4076, 1601, 2183, 4214, 5366, 5434, 6709, 2421, 4247, 5722, 1115, 1730, 6673, 156, 2011, 4416, 4661, 6511, 4411, 821, 6246, 3934, 5711, 3233, 3738, 4561, 3780, 6288, 3115, 7155, 7603, 1932, 6387, 6001, 4376, 2393, 5025, 660, 7634, 1978, 2398, 2826, 2679, 1466, 1953, 3887, 5681, 2945, 2481, 6552, 6096, 1969, 5544, 133, 2313, 5148, 3875, 1050, 960, 721, 2129, 6395, 4106, 1809, 1882, 6491, 7103, 2490, 2810, 3378, 2922, 269, 4468, 1162, 6523, 2106, 5505, 3292, 6605, 3836, 1188, 5752, 2627, 3829, 3616, 1085, 214, 5685, 5261, 879, 4070, 5183, 459, 5777, 4532, 3973, 6037, 2278, 2687, 1388, 6664, 966, 731, 1808, 7703, 5302, 5622, 2637, 5146, 3617, 5720, 5260, 7490, 2428, 7268, 6915, 5690, 6363, 3527, 4800, 1167, 3993, 93, 7816, 1116, 6634, 6411, 6616, 6299, 1866, 7400, 4527, 1528, 7801, 218, 3487, 6009, 1686, 4248, 5258, 3236, 5489, 6993, 6925, 3221, 7668, 4051, 4200, 5321, 5835, 3305, 5628, 7121, 7601, 4013, 540, 4568, 2281, 4550, 4308, 3768, 7774, 6198, 7717, 6145, 3301, 2139, 3702, 1794, 4460, 4301, 4590, 6147, 1410, 6090, 3237, 1934, 4274, 2560, 7450, 3150, 1019, 5798, 6563, 4595, 4179, 7684, 7329, 4963, 246, 4914, 1107, 4038, 1278, 6366, 1681, 5522, 7700, 5959, 6868, 1395, 6115, 5638, 6055, 3373, 1993, 2383, 4570, 6988, 5950, 3783, 7571, 7102, 6711, 49, 4062, 1408, 7191, 5324, 2777, 5374, 3084, 1146, 257, 2682, 4973, 2172, 761, 6817, 689, 655, 4029, 6140, 5571, 1468, 3522, 3076, 4412, 335, 6146, 4519, 2025, 2921, 5526, 4988, 4856, 3120, 3100, 1049, 2537, 3269, 3954, 5192, 7577, 1393, 4699, 4128, 3752, 598, 7110, 6289, 3026, 2047, 871, 150, 1053, 271, 2900, 6989, 4658, 4309, 4122, 908, 5157, 6448, 6092, 3695, 853, 7369, 3230, 1226, 5673, 4167, 3576, 4110, 5182, 1465, 2425, 7676, 1944, 6992, 5129, 5398, 6936, 1745, 3050, 1074, 3553, 1148, 129, 5801, 2423, 896, 7611, 276, 7596, 2063, 4520, 2834, 3610, 7808, 1719, 3252, 2364, 1420, 3079, 1632, 1108, 1297, 503, 2722, 6942, 3663, 7307, 37, 4774, 3764, 6719, 2968, 6286, 2178, 5886, 920, 2157, 4627, 4576, 3168, 2014, 5423, 7772, 1284, 2124, 4134, 3475, 1999, 3501, 1772, 1032, 7541, 1149, 1322, 189, 1718, 5724, 4778, 4773, 1181, 1853, 6878, 7447, 94, 4993, 6666, 970, 5732, 726, 5735, 44, 6996, 1506, 5384, 3855, 3714, 1773, 2774, 5862, 3719, 4298, 250, 2535, 4404, 6869, 2568, 7499, 2275, 4560, 6808, 6949, 6967, 3925, 1305, 1505, 3689, 6609, 607, 233, 1090, 5300, 2648, 2756, 1469, 3254, 4382, 4077, 6979, 7483, 7157, 4504, 4711, 3524, 7542, 6663, 5757, 4232, 6637, 4408, 3056, 3136, 5878, 3421, 3118, 2773, 2974, 3781, 2467, 644, 4429, 858, 4385, 3436, 7651, 7024, 1519, 1059, 7715, 1587, 3451, 95, 860, 4866, 543, 119, 392, 1665, 1372, 3711, 7044, 1320, 7785, 5084, 3141, 4321, 1716, 6133, 4108, 4188, 4757, 4715, 4185, 3329, 4486, 6409, 2656, 446, 4897, 6961, 5601, 2835, 89, 1936, 6449, 3970, 6352, 6460, 7477, 3461, 3046, 6308, 2811, 602, 5949, 6101, 3209, 1947, 290, 5373, 4883, 733, 5124, 6057, 7343, 670, 5193, 1793, 3932, 3401, 3569, 6631, 4551, 1346, 4055, 4569, 3469, 7319, 3612, 5457, 7220, 5967, 2376, 4854, 2187, 1212, 5552, 500, 7264, 7724, 3231, 1411, 5890, 448, 5431, 1523, 4088, 5965, 7391, 5653, 4037, 642, 2915, 7271, 7205, 3971, 2860, 210, 1588, 185, 5942, 1687, 2422, 7452, 5774, 7569, 454, 5067, 5649, 1307, 30, 4244, 159, 6927, 2488, 4783, 7020, 6558, 1424, 5793, 4271, 6976, 4476, 863, 3901, 3002, 4743, 499, 4030, 5556, 5932, 4791, 4153, 5166, 3811, 2237, 5768, 5843, 5609, 4444, 6335, 3222, 3682, 5289, 4323, 4120, 7126, 6047, 5623, 5657, 6948, 3243, 2026, 1111, 4317, 7648, 4240, 6027, 3496, 7449, 1061, 4782, 3163, 6826, 6105, 5716, 5993, 3042, 5227, 475, 728, 6502, 1497, 4923, 547, 6163, 4815, 7081, 1478, 3392, 1370, 3409, 348, 2825, 1013, 6632, 3239, 3096, 1375, 6568, 2037, 6613, 3825, 6882, 6252, 6005, 366, 5734, 3242, 2605, 2717, 6442, 7013, 4499, 4835, 5931, 7381, 3408, 3302, 2838, 262, 5131, 3155, 2464, 7775, 4160, 6642, 3156, 443, 6405, 3821, 1486, 7435, 1091, 3341, 1348, 2092, 6797, 6370, 7512, 787, 6946, 3625, 5464, 1172, 2764, 6969, 5189, 3762, 3545, 2976, 7375, 3135, 3716, 3604, 6102, 2653, 7291, 4881, 6965, 6416, 7661, 2260, 6428, 3226, 64, 678, 5499, 4495, 1816, 2373, 1801, 5636, 7654, 6036, 3427, 5470, 5688, 6588, 1593, 4148, 561, 2855, 7767, 7776, 5090, 6785, 1112, 6221, 154, 2367, 5733, 5756, 4754, 409, 6279, 846, 3175, 4597, 3173, 7027, 1301, 5133, 1894, 5091, 7149, 4553, 7555, 2684, 1048, 552, 488, 6082, 7551, 7798, 6325, 3653, 3316, 57, 3529, 5158, 864, 7348, 340, 5542, 3339, 7315, 4455, 3799, 4642, 628, 6006, 4310, 4750, 425, 4502, 6058, 2862, 4333, 3102, 4714, 3028, 5913, 1704, 6113, 611, 7669, 3500, 4340, 802, 2547, 2388, 1201, 4940, 3504, 103, 6322, 5600, 7289, 7037, 1921, 3190, 805, 4670, 1219, 590, 6103, 7374, 6374, 4981, 1102, 4674, 4371, 7350, 1685, 5459, 3904, 7279, 1286, 6777, 4002, 6651, 6966, 7413, 1851, 5093, 3828, 1480, 4864, 1464, 4482, 2426, 994, 1885, 6791, 7061, 1654, 7188, 7666, 6195, 799, 3990, 3866, 827, 2229, 4074, 3732, 718, 4025, 4393, 6194, 2937, 7752, 5918, 2791, 5568, 6329, 2528, 42, 423, 6960, 6559, 199, 7398, 3450, 7731, 511, 5486, 7548, 6899, 3104, 2521, 3318, 5516, 3279, 4398, 2020, 880, 1211, 3643, 571, 3040, 4184, 2864, 6157, 5472, 606, 4426, 3142, 6454, 3871, 725, 2577, 295, 7001, 4100, 6357, 7003, 1981, 2538, 7825, 1081, 457, 258, 3578, 1555, 5532, 157, 1017, 3064, 7559, 4917, 2358, 6620, 3801, 6208, 5407, 3765, 2195, 5266, 2127, 3850, 4985, 7837, 4734, 1335, 3959, 4727, 2795, 7766, 972, 4103, 7052, 7393, 7600, 3225, 559, 6097, 3215, 5665, 1265, 4953, 6879, 2053, 2767, 208, 1911, 1522, 2848, 3769, 3265, 653, 5701, 5629, 5726, 2602, 2844, 3317, 1621, 1084, 2034, 5534, 1179, 5620, 6652, 3984, 2295, 703, 5759, 3806, 1917, 1508, 480, 6377, 2005, 5037, 3205, 558, 3704, 1031, 421, 4779, 7175, 3839, 7245, 5804, 2283, 3452, 114, 1990, 7063, 6951, 3599, 4318, 1316, 5763, 4831, 2872, 3615, 3137, 7360, 1124, 4034, 7694, 6173, 2078, 3570, 1984, 2149, 6534, 3361, 3941, 7618, 4947, 991, 4677, 7183, 5033, 2748, 7388, 7549, 1827, 20, 4285, 3364, 3774, 4563, 3391, 6602, 5492, 2916, 1694, 3923, 7341, 7444, 3785, 3127, 5408, 2985, 7560, 1339, 5224, 296, 3558, 3484, 1566, 3116, 4151, 6189, 4621, 3849, 1097, 7664, 4336, 6258, 763, 5055, 5771, 7028, 2831, 2142, 693, 5507, 4939, 4415, 5528, 1488, 2262, 336, 407, 6682, 3712, 1044, 3048, 4467, 4494, 3912, 1586, 5910, 2530, 6380, 2046, 4738, 5919, 5401, 7379, 6445, 3270, 6, 439, 351, 828, 883, 5424, 2735, 3472, 1040, 2940, 4972, 5559, 5674, 5696, 7518, 6805, 248, 7250, 2799, 1443, 2254, 3921, 7049, 4753, 1645, 6931, 91, 2691, 6323, 155, 6441, 4474, 1451, 7587, 6073, 7046, 142, 7615, 7062, 420, 5508, 1199, 3594, 6755, 6950, 4770, 4645, 7373, 6840, 432, 484, 3709, 3387, 4720, 2314, 777, 410, 5106, 4174, 5081, 984, 179, 3750, 7500, 5162, 3571, 2640, 4513, 1292, 7469, 692, 2689, 4710, 7210, 5747, 3384, 2412, 5071, 6829, 3948, 7231, 7417, 6328, 3199, 7667, 6715, 4436, 6459, 4739, 2719, 190, 5922, 1906, 291, 6984, 7019, 641, 3582, 1729, 5119, 1551, 6412, 1510, 3633, 734, 6347, 469, 1377, 2828, 3247, 3094, 4517, 6667, 4425, 4007, 2711, 2724, 3608, 1617, 435, 1869, 952, 5764, 2359, 6124, 1389, 6543, 280, 1672, 4784, 6484, 6162, 1473, 253, 1504, 5924, 3872, 4458, 5683, 249, 4197, 3145, 4918, 5527, 4573, 5718, 2438, 5524, 118, 2852, 7581, 1228, 4747, 627, 4441, 7216, 1571, 2027, 6419, 130, 2999, 648, 1363, 6917, 2308, 7302, 7699, 5367, 234, 428, 824, 3744, 2815, 752, 2816, 1638, 1077, 3424, 4085, 3167, 2565, 4064, 572, 664, 2248, 6874, 3211, 2966, 4238, 6452, 6076, 338, 2868, 2806, 2904, 597, 2329, 5639, 4143, 4386, 2869, 3773, 2790, 4522, 5072, 4756, 5755, 6390, 1412, 7134, 5497, 1776, 1554, 4855, 5934, 7726, 6757, 5120, 1920, 6593, 1247, 720, 4457, 6301, 1856, 2468, 6796, 5046, 1276, 5105, 6202, 6180, 5906, 6393, 7612, 2175, 7470, 3128, 3936, 2368, 2947, 754, 6029, 6764, 7226, 7841, 2036, 2840, 273, 3179, 4372, 7185, 516, 5320, 3674, 4233, 2693, 5295, 3182, 5897, 5678, 254, 3262, 1778, 645, 5427, 2249, 5000, 7656, 3249, 2060, 7815, 3557, 3080, 300, 554, 2114, 4838, 4239, 1977, 6134, 3607, 1942, 53, 6810, 7176, 6544, 4769, 5865, 7077, 5019, 3112, 7460, 6876, 6541, 5745, 4237, 4111, 743, 2269, 4470, 4081, 4210, 5589, 6903, 6361, 7137, 6549, 3895, 5861, 3477, 2625, 4601, 2323, 2701, 5054, 7441, 804, 6734, 569, 6635, 903, 3386, 3565, 4999, 7807, 2252, 2334, 7158, 6337, 517, 3734, 6535, 3428, 7253, 2065, 6253, 6364, 4421, 2075, 3810, 4554, 6717, 1988, 168, 5229, 595, 3826, 1331, 3833, 1578, 6272, 3974, 2667, 4544, 6224, 6941, 5286, 687, 3631, 7823, 1890, 1099, 2287, 6821, 5411, 2956, 6857, 2814, 738, 419, 7067, 6466, 6421, 1403, 3938, 568, 7723, 497, 1524, 5306, 2572, 4181, 5929, 6504, 1769, 7095, 2796, 4827, 2246, 7806, 6698, 1189, 7192, 3473, 4706, 817, 3517, 6283, 1673, 7769, 4849, 3129, 4176, 3174, 2055, 3730, 5573, 7014, 6665, 110, 1711, 2738, 1780, 7695, 193, 1951, 5239, 3422, 2280, 7232, 4112, 4995, 5469, 7339, 408, 7194, 5474, 9, 4462, 3071, 2410, 3020, 4751, 3547, 6461, 7099, 6004, 6782, 2369, 7463, 1215, 4792, 3255, 2654, 7087, 7389, 4054, 2099, 6438, 3745, 6492, 331, 6128, 5176, 5679, 5575, 4161, 1676, 3117, 665, 3306, 600, 7693, 7172, 4797, 1130, 5784, 5436, 7489, 3863, 6794, 1489, 6683, 5042, 7141, 6669, 1703, 24, 2524, 783, 3884, 6446, 4545, 5557, 244, 5219, 7386, 565, 6508, 4640, 570, 557, 7322, 7622, 7084, 892, 4611, 957, 3, 765, 4403, 749, 7256, 7058, 84, 4073, 6624, 5335, 7396, 3038, 5808, 3172, 3188, 2318, 4319, 2458, 5060, 7299, 3909, 7744, 7051, 4740, 2706, 930, 4193, 7309, 6297, 1950, 6789, 346, 4256, 6958, 1786, 2453, 1052, 6839, 464, 7582, 36, 3562, 2389, 7240, 672, 5181, 5361, 220, 6048, 4352, 5787, 4384, 6806, 6640, 2447, 4131, 4231, 6501, 2159, 791, 3218, 2808, 4843, 6225, 223, 5362, 3480, 2069, 7002, 730, 474, 3688, 6248, 1101, 7059, 7472, 898, 4152, 3751, 328, 3686, 5899, 662, 7487, 5579, 1332, 7741, 5371, 1023, 1817, 5610, 6465, 1431, 7355, 329, 436, 149, 3812, 7501, 405, 7425, 6209, 2402, 3687, 2887, 7743, 750, 3085, 2198, 1570, 7261, 4169, 3531, 1854, 2045, 3668, 424, 4314, 5152, 2, 3315, 4851, 3655, 4518, 4664, 7285, 3929, 4787, 7273, 3666, 7138, 1557, 1036, 7636, 6962, 5652, 2975, 6580, 1606, 5014, 3919, 928, 5816, 5099, 5013, 61, 7196, 1364, 3109, 4080, 7060, 531, 333, 4257, 3025, 2964, 6274, 888, 2948, 7756, 1467, 7399, 2930, 5277, 5817, 2591, 3982, 3347, 1527, 3581, 3556, 2939, 7670, 6332, 28, 931, 6675, 6845, 4061, 7163, 2168, 4984, 6355, 6804, 977, 840, 560, 1133, 5038, 3258, 81, 2909, 7071, 6621, 1562, 4452, 101, 4941, 3877, 6060, 5139, 6990, 4656, 2002, 6944, 2889, 5670, 1712, 5011, 1843, 5811, 5467, 6159, 6340, 2439, 1585, 6231, 2288, 2996, 5803, 7839, 1625, 3824, 3499, 2608, 6265, 1568, 306, 372, 2430, 5149, 3346, 1777, 1757, 1883, 3433, 403, 476, 5292, 7128, 5245, 5001, 4431, 6205, 1846, 1653, 6166, 3857, 2049, 4363, 1369, 6487, 5343, 4297, 916, 3253, 312, 441, 4742, 1968, 6860, 6881, 2510, 3289, 5549, 5313, 3718, 6033, 7637, 2090, 7197, 5221, 1180, 2463, 2936, 4255, 1888, 3662, 1001, 7505, 757, 2483, 3754, 2573, 1321, 1675, 3438, 7558, 7280, 1324, 6853, 6171, 1492, 1256, 3791, 3873, 1576, 88, 1365, 2908, 3848, 7803, 1746, 107, 2567, 4622, 1302, 4014, 3503, 6815, 7702, 4466, 3146, 2276, 2519, 7203, 2931, 5952, 6820, 7508, 3731, 4510, 1441, 2355, 2759, 4449, 5881, 2371, 231, 5900, 87, 4191, 6114, 3304, 6238, 1157, 3893, 1192, 7320, 1589, 1378, 7432, 4019, 2554, 5738, 3679, 19, 5155, 6059, 583, 4420, 7481, 1066, 3540, 1507, 3354, 2152, 4109, 1220, 4929, 4268, 1384, 5455, 7365, 7553, 3457, 5355, 1414, 889, 3728, 3336, 6110, 2264, 4580, 5807, 1895, 1428, 2954, 1787, 5416, 1958, 2138, 1423, 1759, 5868, 3463, 5994, 6406, 6111, 5496, 3193, 6084, 4434, 6199, 6731, 6321, 5668, 7478, 2564, 4187, 2357, 2150, 6940, 3502, 6739, 5171, 3031, 2787, 1836, 1873, 4096, 4882, 4362, 6528, 47, 866, 1006, 5164, 5750, 1940, 6141, 2569, 3883, 6294, 3051, 5694, 7281, 7252, 5278, 426, 3399, 2769, 11, 6178, 1996, 5080, 7204, 555, 3267, 2182, 5661, 2702, 3200, 3212, 3027, 5944, 5815, 5298, 6875, 3283, 6638, 7655, 2849, 4613, 1194, 417, 1597, 3634, 764, 4270, 1383, 5848, 345, 6314, 173, 6763, 7142, 2775, 6527, 4139, 3016, 5707, 1406, 4780, 989, 1748, 7346, 5517, 6271, 3437, 2457, 2800, 4395, 513, 92, 3013, 5137, 1300, 786, 3456, 1848, 141, 6247, 7770, 7779, 988, 429, 5314, 1864, 550, 2469, 4543, 3951, 140, 2343, 6615, 380, 3197, 2978, 5785, 671, 7148, 1145, 6315, 785, 830, 6261, 1680, 7466, 7357, 5184, 669, 7525, 6212, 2801, 4050, 7173, 2562, 5841, 2633, 711, 1086, 6389, 1812, 6062, 6901, 2837, 7674, 4938, 6240, 2920, 1415, 4166, 7406, 7682, 6211, 7451, 1344, 4123, 1495, 7356, 4259, 5378, 2351, 353, 3227, 6498, 7516, 3181, 3725, 1543, 868, 5713, 3561, 5103, 5618, 1861, 5089, 2416, 1642, 6659, 5662, 5754, 2244, 6566, 3201, 1667, 4116, 5075, 1057, 4012, 4056, 6582, 4220, 1697, 519, 5127, 2302, 2611, 4758, 5818, 6127, 2993, 6495, 7791, 1948, 1455, 5799, 7810, 4861, 3374, 1283, 5857, 4448, 3551, 1207, 1790, 6216, 3994, 3278, 6266, 6584, 6000, 5357, 5479, 7584, 1536, 317, 6071, 2953, 7283, 7496, 3095, 6623, 2208, 2273, 6206, 5056, 959, 7000, 7078, 5926, 3467, 1083, 7305, 5285, 7754, 6824, 4945, 7498, 2726, 4626, 7689, 6052, 2265, 2615, 1541, 1641, 1902, 1727, 4328, 6799, 4530, 1825, 1240, 6040, 7390, 5721, 3755, 5475, 1619, 5288, 4655, 708, 2518, 4549, 5572, 974, 6239, 5040, 1368, 1288, 2112, 7347, 3019, 2070, 255, 634, 4367, 7805, 3996, 793, 1487, 4357, 5364, 3880, 7486, 7531, 2024, 7488, 6410, 7290, 138, 6456, 2328, 2641, 183, 739, 1726, 5824, 1832, 2665, 2459, 5717, 2261, 4846, 251, 5051, 5460, 910, 1184, 2788, 2760, 2750, 6351, 6316, 4654, 3638, 3273, 2674, 7045, 1922, 7272, 438, 1246, 7106, 3552, 5751, 2394, 3101, 4848, 5977, 5257, 4473, 5267, 6304, 6982, 5782, 7092, 6210, 6422, 4098, 5595, 7202, 4136, 4685, 4491, 4125, 3635, 5590, 3159, 760, 4020, 3300, 2925, 1319, 3790, 2199, 2942, 1964, 2218, 4952, 1394, 3161, 1169]\n",
      "0        661\n",
      "1       4477\n",
      "2       1046\n",
      "3        631\n",
      "4       6533\n",
      "        ... \n",
      "2348    2218\n",
      "2349    4952\n",
      "2350    1394\n",
      "2351    3161\n",
      "2352    1169\n",
      "Name: id, Length: 2353, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# import test set\n",
    "test_metadata = pd.read_csv(\"Data/test/test_metadata.csv\")\n",
    "test_paths = test_metadata[\"image_path\"]\n",
    "test_index = test_metadata[\"id\"]\n",
    "\n",
    "test_data = []\n",
    "test_id = []\n",
    "\n",
    "for i in range(len(test_paths)):\n",
    "    try:\n",
    "        # open image\n",
    "        image = Image.open(f\"Data/test/{test_paths.iloc[i]}\")\n",
    "        # resize image to (50, 50)\n",
    "        image = image.resize(rescale_size)\n",
    "        image = np.array(image)\n",
    "        test_data.append(image)\n",
    "        test_id.append(test_index.iloc[i])\n",
    "    except:\n",
    "        print(f\"error loading image {test_paths.iloc[i]}\")\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict classes of test data\n",
    "with tf.device('/GPU:0'):\n",
    "    pred = np.argmax(model.predict(test_data), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42c35519",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'id': test_index, 'ClassId': pred})\n",
    "result.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
