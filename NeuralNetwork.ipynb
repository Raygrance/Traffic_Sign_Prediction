{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3318943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from skimage import io, color\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel, sobel_h, sobel_v\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df39b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.567237609329446\n",
      "50.05648688046647\n"
     ]
    }
   ],
   "source": [
    "# calculate average size to help inform a size to resize all images to\n",
    "imagex = 0\n",
    "imagey = 0\n",
    "for i in range(1, 5489):    \n",
    "    image = Image.open(f'Data/train/img_00{i:04d}.jpg')\n",
    "    imagex += image.size[0]\n",
    "    imagey += image.size[1]\n",
    "    \n",
    "print(imagex/5488) # 50.567237609329446\n",
    "print(imagey/5488) # 50.05648688046647\n",
    "\n",
    "# scale to 50 x 50\n",
    "rescale_size = (50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fbca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import paths and labels\n",
    "train_metadata = pd.read_csv(\"Data/train/train_metadata.csv\", index_col=\"id\")\n",
    "train_paths = train_metadata[\"image_path\"]\n",
    "train_class = train_metadata[\"ClassId\"]\n",
    "\n",
    "# import test set\n",
    "test_metadata = pd.read_csv(\"Data/test/test_metadata.csv\")\n",
    "test_paths = test_metadata[\"image_path\"]\n",
    "test_index = test_metadata[\"id\"]\n",
    "\n",
    "rescale_size = (50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe1ac6",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ed4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image files as pixel RGB values\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(len(train_paths)):\n",
    "    try:\n",
    "        # open image\n",
    "        image = Image.open(f\"Data/train/{train_paths.iloc[i]}\")\n",
    "        # resize image to (50, 50)\n",
    "        image = image.resize(rescale_size)\n",
    "        image = np.array(image)\n",
    "        train_data.append(image)\n",
    "        train_labels.append(train_class.iloc[i])\n",
    "    except:\n",
    "        print(f\"error loading image {train_paths.iloc[i]}\")\n",
    "\n",
    "data = np.array(train_data)\n",
    "labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has shape: (5488, 50, 50, 3)\n",
      "labels have shape: (5488,)\n",
      "X_train has shape: (4390, 50, 50, 3)\n",
      "X_test has shape: (1098, 50, 50, 3)\n",
      "y_train has shape: (4390,)\n",
      "y_test has shape: (1098,)\n",
      "(4390, 43)\n"
     ]
    }
   ],
   "source": [
    "# sanity check data\n",
    "\n",
    "print(f\"data has shape: {data.shape}\")\n",
    "print(f\"labels have shape: {labels.shape}\")\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=69)\n",
    "\n",
    "print(f\"X_train has shape: {X_train.shape}\")\n",
    "print(f\"X_test has shape: {X_test.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de68bbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayzh\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,389,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,059</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m51,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m8,389,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │        \u001b[38;5;34m22,059\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,833,899</span> (33.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,833,899\u001b[0m (33.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,833,899</span> (33.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,833,899\u001b[0m (33.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.15))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#M odel display\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dd5488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.0855 - loss: 14.9181 - val_accuracy: 0.4299 - val_loss: 2.1528\n",
      "Epoch 2/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.5303 - loss: 1.8151 - val_accuracy: 0.8215 - val_loss: 0.8276\n",
      "Epoch 3/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.8068 - loss: 0.6909 - val_accuracy: 0.9308 - val_loss: 0.3511\n",
      "Epoch 4/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.9052 - loss: 0.3525 - val_accuracy: 0.9353 - val_loss: 0.2423\n",
      "Epoch 5/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - accuracy: 0.9348 - loss: 0.2465 - val_accuracy: 0.9472 - val_loss: 0.2105\n",
      "Epoch 6/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.9421 - loss: 0.2191 - val_accuracy: 0.9599 - val_loss: 0.1975\n",
      "Epoch 7/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9605 - loss: 0.1597 - val_accuracy: 0.9545 - val_loss: 0.1896\n",
      "Epoch 8/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.9643 - loss: 0.1286 - val_accuracy: 0.9599 - val_loss: 0.2009\n",
      "Epoch 9/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.9670 - loss: 0.1193 - val_accuracy: 0.9699 - val_loss: 0.0994\n",
      "Epoch 10/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9801 - loss: 0.0773 - val_accuracy: 0.9645 - val_loss: 0.1545\n",
      "Epoch 11/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9795 - loss: 0.0817 - val_accuracy: 0.9545 - val_loss: 0.1880\n",
      "Epoch 12/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.9699 - loss: 0.1107 - val_accuracy: 0.9554 - val_loss: 0.1931\n",
      "Epoch 13/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.9764 - loss: 0.0819 - val_accuracy: 0.9736 - val_loss: 0.1090\n",
      "Epoch 14/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step - accuracy: 0.9810 - loss: 0.0763 - val_accuracy: 0.9718 - val_loss: 0.0963\n",
      "Epoch 15/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.9902 - loss: 0.0338 - val_accuracy: 0.9763 - val_loss: 0.0917\n",
      "Epoch 16/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.9879 - loss: 0.0486 - val_accuracy: 0.9718 - val_loss: 0.1224\n",
      "Epoch 17/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9858 - loss: 0.0544 - val_accuracy: 0.9763 - val_loss: 0.0997\n",
      "Epoch 18/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9948 - loss: 0.0202 - val_accuracy: 0.9590 - val_loss: 0.1962\n",
      "Epoch 19/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 221ms/step - accuracy: 0.9879 - loss: 0.0395 - val_accuracy: 0.9718 - val_loss: 0.1051\n",
      "Epoch 20/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.9882 - loss: 0.0423 - val_accuracy: 0.9736 - val_loss: 0.1189\n",
      "Epoch 21/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.9895 - loss: 0.0337 - val_accuracy: 0.9809 - val_loss: 0.0961\n",
      "Epoch 22/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - accuracy: 0.9919 - loss: 0.0317 - val_accuracy: 0.9772 - val_loss: 0.1048\n",
      "Epoch 23/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 206ms/step - accuracy: 0.9937 - loss: 0.0318 - val_accuracy: 0.9663 - val_loss: 0.1611\n",
      "Epoch 24/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.9839 - loss: 0.0571 - val_accuracy: 0.9772 - val_loss: 0.1171\n",
      "Epoch 25/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.9865 - loss: 0.0608 - val_accuracy: 0.9681 - val_loss: 0.1544\n",
      "Epoch 26/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.9863 - loss: 0.0645 - val_accuracy: 0.9645 - val_loss: 0.1531\n",
      "Epoch 27/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - accuracy: 0.9788 - loss: 0.0723 - val_accuracy: 0.9699 - val_loss: 0.1302\n",
      "Epoch 28/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.9867 - loss: 0.0498 - val_accuracy: 0.9727 - val_loss: 0.1547\n",
      "Epoch 29/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - accuracy: 0.9842 - loss: 0.0862 - val_accuracy: 0.9572 - val_loss: 0.2248\n",
      "Epoch 30/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - accuracy: 0.9702 - loss: 0.1077 - val_accuracy: 0.9690 - val_loss: 0.1705\n",
      "Epoch 31/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - accuracy: 0.9773 - loss: 0.0973 - val_accuracy: 0.9617 - val_loss: 0.2220\n",
      "Epoch 32/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9855 - loss: 0.0831 - val_accuracy: 0.9663 - val_loss: 0.1656\n",
      "Epoch 33/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.9897 - loss: 0.0454 - val_accuracy: 0.9681 - val_loss: 0.1768\n",
      "Epoch 34/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.9898 - loss: 0.0413 - val_accuracy: 0.9754 - val_loss: 0.1315\n",
      "Epoch 35/35\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.9954 - loss: 0.0204 - val_accuracy: 0.9727 - val_loss: 0.1466\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "with tf.device('/GPU:0'):\n",
    "    epochs = 35\n",
    "    history1 = model.fit(X_train, y_train, batch_size=128, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2353, 50, 50, 3)\n",
      "[np.int64(661), np.int64(4477), np.int64(1046), np.int64(631), np.int64(6533), np.int64(2899), np.int64(1941), np.int64(5749), np.int64(588), np.int64(1333), np.int64(5826), np.int64(7493), np.int64(4306), np.int64(3429), np.int64(1191), np.int64(4076), np.int64(1601), np.int64(2183), np.int64(4214), np.int64(5366), np.int64(5434), np.int64(6709), np.int64(2421), np.int64(4247), np.int64(5722), np.int64(1115), np.int64(1730), np.int64(6673), np.int64(156), np.int64(2011), np.int64(4416), np.int64(4661), np.int64(6511), np.int64(4411), np.int64(821), np.int64(6246), np.int64(3934), np.int64(5711), np.int64(3233), np.int64(3738), np.int64(4561), np.int64(3780), np.int64(6288), np.int64(3115), np.int64(7155), np.int64(7603), np.int64(1932), np.int64(6387), np.int64(6001), np.int64(4376), np.int64(2393), np.int64(5025), np.int64(660), np.int64(7634), np.int64(1978), np.int64(2398), np.int64(2826), np.int64(2679), np.int64(1466), np.int64(1953), np.int64(3887), np.int64(5681), np.int64(2945), np.int64(2481), np.int64(6552), np.int64(6096), np.int64(1969), np.int64(5544), np.int64(133), np.int64(2313), np.int64(5148), np.int64(3875), np.int64(1050), np.int64(960), np.int64(721), np.int64(2129), np.int64(6395), np.int64(4106), np.int64(1809), np.int64(1882), np.int64(6491), np.int64(7103), np.int64(2490), np.int64(2810), np.int64(3378), np.int64(2922), np.int64(269), np.int64(4468), np.int64(1162), np.int64(6523), np.int64(2106), np.int64(5505), np.int64(3292), np.int64(6605), np.int64(3836), np.int64(1188), np.int64(5752), np.int64(2627), np.int64(3829), np.int64(3616), np.int64(1085), np.int64(214), np.int64(5685), np.int64(5261), np.int64(879), np.int64(4070), np.int64(5183), np.int64(459), np.int64(5777), np.int64(4532), np.int64(3973), np.int64(6037), np.int64(2278), np.int64(2687), np.int64(1388), np.int64(6664), np.int64(966), np.int64(731), np.int64(1808), np.int64(7703), np.int64(5302), np.int64(5622), np.int64(2637), np.int64(5146), np.int64(3617), np.int64(5720), np.int64(5260), np.int64(7490), np.int64(2428), np.int64(7268), np.int64(6915), np.int64(5690), np.int64(6363), np.int64(3527), np.int64(4800), np.int64(1167), np.int64(3993), np.int64(93), np.int64(7816), np.int64(1116), np.int64(6634), np.int64(6411), np.int64(6616), np.int64(6299), np.int64(1866), np.int64(7400), np.int64(4527), np.int64(1528), np.int64(7801), np.int64(218), np.int64(3487), np.int64(6009), np.int64(1686), np.int64(4248), np.int64(5258), np.int64(3236), np.int64(5489), np.int64(6993), np.int64(6925), np.int64(3221), np.int64(7668), np.int64(4051), np.int64(4200), np.int64(5321), np.int64(5835), np.int64(3305), np.int64(5628), np.int64(7121), np.int64(7601), np.int64(4013), np.int64(540), np.int64(4568), np.int64(2281), np.int64(4550), np.int64(4308), np.int64(3768), np.int64(7774), np.int64(6198), np.int64(7717), np.int64(6145), np.int64(3301), np.int64(2139), np.int64(3702), np.int64(1794), np.int64(4460), np.int64(4301), np.int64(4590), np.int64(6147), np.int64(1410), np.int64(6090), np.int64(3237), np.int64(1934), np.int64(4274), np.int64(2560), np.int64(7450), np.int64(3150), np.int64(1019), np.int64(5798), np.int64(6563), np.int64(4595), np.int64(4179), np.int64(7684), np.int64(7329), np.int64(4963), np.int64(246), np.int64(4914), np.int64(1107), np.int64(4038), np.int64(1278), np.int64(6366), np.int64(1681), np.int64(5522), np.int64(7700), np.int64(5959), np.int64(6868), np.int64(1395), np.int64(6115), np.int64(5638), np.int64(6055), np.int64(3373), np.int64(1993), np.int64(2383), np.int64(4570), np.int64(6988), np.int64(5950), np.int64(3783), np.int64(7571), np.int64(7102), np.int64(6711), np.int64(49), np.int64(4062), np.int64(1408), np.int64(7191), np.int64(5324), np.int64(2777), np.int64(5374), np.int64(3084), np.int64(1146), np.int64(257), np.int64(2682), np.int64(4973), np.int64(2172), np.int64(761), np.int64(6817), np.int64(689), np.int64(655), np.int64(4029), np.int64(6140), np.int64(5571), np.int64(1468), np.int64(3522), np.int64(3076), np.int64(4412), np.int64(335), np.int64(6146), np.int64(4519), np.int64(2025), np.int64(2921), np.int64(5526), np.int64(4988), np.int64(4856), np.int64(3120), np.int64(3100), np.int64(1049), np.int64(2537), np.int64(3269), np.int64(3954), np.int64(5192), np.int64(7577), np.int64(1393), np.int64(4699), np.int64(4128), np.int64(3752), np.int64(598), np.int64(7110), np.int64(6289), np.int64(3026), np.int64(2047), np.int64(871), np.int64(150), np.int64(1053), np.int64(271), np.int64(2900), np.int64(6989), np.int64(4658), np.int64(4309), np.int64(4122), np.int64(908), np.int64(5157), np.int64(6448), np.int64(6092), np.int64(3695), np.int64(853), np.int64(7369), np.int64(3230), np.int64(1226), np.int64(5673), np.int64(4167), np.int64(3576), np.int64(4110), np.int64(5182), np.int64(1465), np.int64(2425), np.int64(7676), np.int64(1944), np.int64(6992), np.int64(5129), np.int64(5398), np.int64(6936), np.int64(1745), np.int64(3050), np.int64(1074), np.int64(3553), np.int64(1148), np.int64(129), np.int64(5801), np.int64(2423), np.int64(896), np.int64(7611), np.int64(276), np.int64(7596), np.int64(2063), np.int64(4520), np.int64(2834), np.int64(3610), np.int64(7808), np.int64(1719), np.int64(3252), np.int64(2364), np.int64(1420), np.int64(3079), np.int64(1632), np.int64(1108), np.int64(1297), np.int64(503), np.int64(2722), np.int64(6942), np.int64(3663), np.int64(7307), np.int64(37), np.int64(4774), np.int64(3764), np.int64(6719), np.int64(2968), np.int64(6286), np.int64(2178), np.int64(5886), np.int64(920), np.int64(2157), np.int64(4627), np.int64(4576), np.int64(3168), np.int64(2014), np.int64(5423), np.int64(7772), np.int64(1284), np.int64(2124), np.int64(4134), np.int64(3475), np.int64(1999), np.int64(3501), np.int64(1772), np.int64(1032), np.int64(7541), np.int64(1149), np.int64(1322), np.int64(189), np.int64(1718), np.int64(5724), np.int64(4778), np.int64(4773), np.int64(1181), np.int64(1853), np.int64(6878), np.int64(7447), np.int64(94), np.int64(4993), np.int64(6666), np.int64(970), np.int64(5732), np.int64(726), np.int64(5735), np.int64(44), np.int64(6996), np.int64(1506), np.int64(5384), np.int64(3855), np.int64(3714), np.int64(1773), np.int64(2774), np.int64(5862), np.int64(3719), np.int64(4298), np.int64(250), np.int64(2535), np.int64(4404), np.int64(6869), np.int64(2568), np.int64(7499), np.int64(2275), np.int64(4560), np.int64(6808), np.int64(6949), np.int64(6967), np.int64(3925), np.int64(1305), np.int64(1505), np.int64(3689), np.int64(6609), np.int64(607), np.int64(233), np.int64(1090), np.int64(5300), np.int64(2648), np.int64(2756), np.int64(1469), np.int64(3254), np.int64(4382), np.int64(4077), np.int64(6979), np.int64(7483), np.int64(7157), np.int64(4504), np.int64(4711), np.int64(3524), np.int64(7542), np.int64(6663), np.int64(5757), np.int64(4232), np.int64(6637), np.int64(4408), np.int64(3056), np.int64(3136), np.int64(5878), np.int64(3421), np.int64(3118), np.int64(2773), np.int64(2974), np.int64(3781), np.int64(2467), np.int64(644), np.int64(4429), np.int64(858), np.int64(4385), np.int64(3436), np.int64(7651), np.int64(7024), np.int64(1519), np.int64(1059), np.int64(7715), np.int64(1587), np.int64(3451), np.int64(95), np.int64(860), np.int64(4866), np.int64(543), np.int64(119), np.int64(392), np.int64(1665), np.int64(1372), np.int64(3711), np.int64(7044), np.int64(1320), np.int64(7785), np.int64(5084), np.int64(3141), np.int64(4321), np.int64(1716), np.int64(6133), np.int64(4108), np.int64(4188), np.int64(4757), np.int64(4715), np.int64(4185), np.int64(3329), np.int64(4486), np.int64(6409), np.int64(2656), np.int64(446), np.int64(4897), np.int64(6961), np.int64(5601), np.int64(2835), np.int64(89), np.int64(1936), np.int64(6449), np.int64(3970), np.int64(6352), np.int64(6460), np.int64(7477), np.int64(3461), np.int64(3046), np.int64(6308), np.int64(2811), np.int64(602), np.int64(5949), np.int64(6101), np.int64(3209), np.int64(1947), np.int64(290), np.int64(5373), np.int64(4883), np.int64(733), np.int64(5124), np.int64(6057), np.int64(7343), np.int64(670), np.int64(5193), np.int64(1793), np.int64(3932), np.int64(3401), np.int64(3569), np.int64(6631), np.int64(4551), np.int64(1346), np.int64(4055), np.int64(4569), np.int64(3469), np.int64(7319), np.int64(3612), np.int64(5457), np.int64(7220), np.int64(5967), np.int64(2376), np.int64(4854), np.int64(2187), np.int64(1212), np.int64(5552), np.int64(500), np.int64(7264), np.int64(7724), np.int64(3231), np.int64(1411), np.int64(5890), np.int64(448), np.int64(5431), np.int64(1523), np.int64(4088), np.int64(5965), np.int64(7391), np.int64(5653), np.int64(4037), np.int64(642), np.int64(2915), np.int64(7271), np.int64(7205), np.int64(3971), np.int64(2860), np.int64(210), np.int64(1588), np.int64(185), np.int64(5942), np.int64(1687), np.int64(2422), np.int64(7452), np.int64(5774), np.int64(7569), np.int64(454), np.int64(5067), np.int64(5649), np.int64(1307), np.int64(30), np.int64(4244), np.int64(159), np.int64(6927), np.int64(2488), np.int64(4783), np.int64(7020), np.int64(6558), np.int64(1424), np.int64(5793), np.int64(4271), np.int64(6976), np.int64(4476), np.int64(863), np.int64(3901), np.int64(3002), np.int64(4743), np.int64(499), np.int64(4030), np.int64(5556), np.int64(5932), np.int64(4791), np.int64(4153), np.int64(5166), np.int64(3811), np.int64(2237), np.int64(5768), np.int64(5843), np.int64(5609), np.int64(4444), np.int64(6335), np.int64(3222), np.int64(3682), np.int64(5289), np.int64(4323), np.int64(4120), np.int64(7126), np.int64(6047), np.int64(5623), np.int64(5657), np.int64(6948), np.int64(3243), np.int64(2026), np.int64(1111), np.int64(4317), np.int64(7648), np.int64(4240), np.int64(6027), np.int64(3496), np.int64(7449), np.int64(1061), np.int64(4782), np.int64(3163), np.int64(6826), np.int64(6105), np.int64(5716), np.int64(5993), np.int64(3042), np.int64(5227), np.int64(475), np.int64(728), np.int64(6502), np.int64(1497), np.int64(4923), np.int64(547), np.int64(6163), np.int64(4815), np.int64(7081), np.int64(1478), np.int64(3392), np.int64(1370), np.int64(3409), np.int64(348), np.int64(2825), np.int64(1013), np.int64(6632), np.int64(3239), np.int64(3096), np.int64(1375), np.int64(6568), np.int64(2037), np.int64(6613), np.int64(3825), np.int64(6882), np.int64(6252), np.int64(6005), np.int64(366), np.int64(5734), np.int64(3242), np.int64(2605), np.int64(2717), np.int64(6442), np.int64(7013), np.int64(4499), np.int64(4835), np.int64(5931), np.int64(7381), np.int64(3408), np.int64(3302), np.int64(2838), np.int64(262), np.int64(5131), np.int64(3155), np.int64(2464), np.int64(7775), np.int64(4160), np.int64(6642), np.int64(3156), np.int64(443), np.int64(6405), np.int64(3821), np.int64(1486), np.int64(7435), np.int64(1091), np.int64(3341), np.int64(1348), np.int64(2092), np.int64(6797), np.int64(6370), np.int64(7512), np.int64(787), np.int64(6946), np.int64(3625), np.int64(5464), np.int64(1172), np.int64(2764), np.int64(6969), np.int64(5189), np.int64(3762), np.int64(3545), np.int64(2976), np.int64(7375), np.int64(3135), np.int64(3716), np.int64(3604), np.int64(6102), np.int64(2653), np.int64(7291), np.int64(4881), np.int64(6965), np.int64(6416), np.int64(7661), np.int64(2260), np.int64(6428), np.int64(3226), np.int64(64), np.int64(678), np.int64(5499), np.int64(4495), np.int64(1816), np.int64(2373), np.int64(1801), np.int64(5636), np.int64(7654), np.int64(6036), np.int64(3427), np.int64(5470), np.int64(5688), np.int64(6588), np.int64(1593), np.int64(4148), np.int64(561), np.int64(2855), np.int64(7767), np.int64(7776), np.int64(5090), np.int64(6785), np.int64(1112), np.int64(6221), np.int64(154), np.int64(2367), np.int64(5733), np.int64(5756), np.int64(4754), np.int64(409), np.int64(6279), np.int64(846), np.int64(3175), np.int64(4597), np.int64(3173), np.int64(7027), np.int64(1301), np.int64(5133), np.int64(1894), np.int64(5091), np.int64(7149), np.int64(4553), np.int64(7555), np.int64(2684), np.int64(1048), np.int64(552), np.int64(488), np.int64(6082), np.int64(7551), np.int64(7798), np.int64(6325), np.int64(3653), np.int64(3316), np.int64(57), np.int64(3529), np.int64(5158), np.int64(864), np.int64(7348), np.int64(340), np.int64(5542), np.int64(3339), np.int64(7315), np.int64(4455), np.int64(3799), np.int64(4642), np.int64(628), np.int64(6006), np.int64(4310), np.int64(4750), np.int64(425), np.int64(4502), np.int64(6058), np.int64(2862), np.int64(4333), np.int64(3102), np.int64(4714), np.int64(3028), np.int64(5913), np.int64(1704), np.int64(6113), np.int64(611), np.int64(7669), np.int64(3500), np.int64(4340), np.int64(802), np.int64(2547), np.int64(2388), np.int64(1201), np.int64(4940), np.int64(3504), np.int64(103), np.int64(6322), np.int64(5600), np.int64(7289), np.int64(7037), np.int64(1921), np.int64(3190), np.int64(805), np.int64(4670), np.int64(1219), np.int64(590), np.int64(6103), np.int64(7374), np.int64(6374), np.int64(4981), np.int64(1102), np.int64(4674), np.int64(4371), np.int64(7350), np.int64(1685), np.int64(5459), np.int64(3904), np.int64(7279), np.int64(1286), np.int64(6777), np.int64(4002), np.int64(6651), np.int64(6966), np.int64(7413), np.int64(1851), np.int64(5093), np.int64(3828), np.int64(1480), np.int64(4864), np.int64(1464), np.int64(4482), np.int64(2426), np.int64(994), np.int64(1885), np.int64(6791), np.int64(7061), np.int64(1654), np.int64(7188), np.int64(7666), np.int64(6195), np.int64(799), np.int64(3990), np.int64(3866), np.int64(827), np.int64(2229), np.int64(4074), np.int64(3732), np.int64(718), np.int64(4025), np.int64(4393), np.int64(6194), np.int64(2937), np.int64(7752), np.int64(5918), np.int64(2791), np.int64(5568), np.int64(6329), np.int64(2528), np.int64(42), np.int64(423), np.int64(6960), np.int64(6559), np.int64(199), np.int64(7398), np.int64(3450), np.int64(7731), np.int64(511), np.int64(5486), np.int64(7548), np.int64(6899), np.int64(3104), np.int64(2521), np.int64(3318), np.int64(5516), np.int64(3279), np.int64(4398), np.int64(2020), np.int64(880), np.int64(1211), np.int64(3643), np.int64(571), np.int64(3040), np.int64(4184), np.int64(2864), np.int64(6157), np.int64(5472), np.int64(606), np.int64(4426), np.int64(3142), np.int64(6454), np.int64(3871), np.int64(725), np.int64(2577), np.int64(295), np.int64(7001), np.int64(4100), np.int64(6357), np.int64(7003), np.int64(1981), np.int64(2538), np.int64(7825), np.int64(1081), np.int64(457), np.int64(258), np.int64(3578), np.int64(1555), np.int64(5532), np.int64(157), np.int64(1017), np.int64(3064), np.int64(7559), np.int64(4917), np.int64(2358), np.int64(6620), np.int64(3801), np.int64(6208), np.int64(5407), np.int64(3765), np.int64(2195), np.int64(5266), np.int64(2127), np.int64(3850), np.int64(4985), np.int64(7837), np.int64(4734), np.int64(1335), np.int64(3959), np.int64(4727), np.int64(2795), np.int64(7766), np.int64(972), np.int64(4103), np.int64(7052), np.int64(7393), np.int64(7600), np.int64(3225), np.int64(559), np.int64(6097), np.int64(3215), np.int64(5665), np.int64(1265), np.int64(4953), np.int64(6879), np.int64(2053), np.int64(2767), np.int64(208), np.int64(1911), np.int64(1522), np.int64(2848), np.int64(3769), np.int64(3265), np.int64(653), np.int64(5701), np.int64(5629), np.int64(5726), np.int64(2602), np.int64(2844), np.int64(3317), np.int64(1621), np.int64(1084), np.int64(2034), np.int64(5534), np.int64(1179), np.int64(5620), np.int64(6652), np.int64(3984), np.int64(2295), np.int64(703), np.int64(5759), np.int64(3806), np.int64(1917), np.int64(1508), np.int64(480), np.int64(6377), np.int64(2005), np.int64(5037), np.int64(3205), np.int64(558), np.int64(3704), np.int64(1031), np.int64(421), np.int64(4779), np.int64(7175), np.int64(3839), np.int64(7245), np.int64(5804), np.int64(2283), np.int64(3452), np.int64(114), np.int64(1990), np.int64(7063), np.int64(6951), np.int64(3599), np.int64(4318), np.int64(1316), np.int64(5763), np.int64(4831), np.int64(2872), np.int64(3615), np.int64(3137), np.int64(7360), np.int64(1124), np.int64(4034), np.int64(7694), np.int64(6173), np.int64(2078), np.int64(3570), np.int64(1984), np.int64(2149), np.int64(6534), np.int64(3361), np.int64(3941), np.int64(7618), np.int64(4947), np.int64(991), np.int64(4677), np.int64(7183), np.int64(5033), np.int64(2748), np.int64(7388), np.int64(7549), np.int64(1827), np.int64(20), np.int64(4285), np.int64(3364), np.int64(3774), np.int64(4563), np.int64(3391), np.int64(6602), np.int64(5492), np.int64(2916), np.int64(1694), np.int64(3923), np.int64(7341), np.int64(7444), np.int64(3785), np.int64(3127), np.int64(5408), np.int64(2985), np.int64(7560), np.int64(1339), np.int64(5224), np.int64(296), np.int64(3558), np.int64(3484), np.int64(1566), np.int64(3116), np.int64(4151), np.int64(6189), np.int64(4621), np.int64(3849), np.int64(1097), np.int64(7664), np.int64(4336), np.int64(6258), np.int64(763), np.int64(5055), np.int64(5771), np.int64(7028), np.int64(2831), np.int64(2142), np.int64(693), np.int64(5507), np.int64(4939), np.int64(4415), np.int64(5528), np.int64(1488), np.int64(2262), np.int64(336), np.int64(407), np.int64(6682), np.int64(3712), np.int64(1044), np.int64(3048), np.int64(4467), np.int64(4494), np.int64(3912), np.int64(1586), np.int64(5910), np.int64(2530), np.int64(6380), np.int64(2046), np.int64(4738), np.int64(5919), np.int64(5401), np.int64(7379), np.int64(6445), np.int64(3270), np.int64(6), np.int64(439), np.int64(351), np.int64(828), np.int64(883), np.int64(5424), np.int64(2735), np.int64(3472), np.int64(1040), np.int64(2940), np.int64(4972), np.int64(5559), np.int64(5674), np.int64(5696), np.int64(7518), np.int64(6805), np.int64(248), np.int64(7250), np.int64(2799), np.int64(1443), np.int64(2254), np.int64(3921), np.int64(7049), np.int64(4753), np.int64(1645), np.int64(6931), np.int64(91), np.int64(2691), np.int64(6323), np.int64(155), np.int64(6441), np.int64(4474), np.int64(1451), np.int64(7587), np.int64(6073), np.int64(7046), np.int64(142), np.int64(7615), np.int64(7062), np.int64(420), np.int64(5508), np.int64(1199), np.int64(3594), np.int64(6755), np.int64(6950), np.int64(4770), np.int64(4645), np.int64(7373), np.int64(6840), np.int64(432), np.int64(484), np.int64(3709), np.int64(3387), np.int64(4720), np.int64(2314), np.int64(777), np.int64(410), np.int64(5106), np.int64(4174), np.int64(5081), np.int64(984), np.int64(179), np.int64(3750), np.int64(7500), np.int64(5162), np.int64(3571), np.int64(2640), np.int64(4513), np.int64(1292), np.int64(7469), np.int64(692), np.int64(2689), np.int64(4710), np.int64(7210), np.int64(5747), np.int64(3384), np.int64(2412), np.int64(5071), np.int64(6829), np.int64(3948), np.int64(7231), np.int64(7417), np.int64(6328), np.int64(3199), np.int64(7667), np.int64(6715), np.int64(4436), np.int64(6459), np.int64(4739), np.int64(2719), np.int64(190), np.int64(5922), np.int64(1906), np.int64(291), np.int64(6984), np.int64(7019), np.int64(641), np.int64(3582), np.int64(1729), np.int64(5119), np.int64(1551), np.int64(6412), np.int64(1510), np.int64(3633), np.int64(734), np.int64(6347), np.int64(469), np.int64(1377), np.int64(2828), np.int64(3247), np.int64(3094), np.int64(4517), np.int64(6667), np.int64(4425), np.int64(4007), np.int64(2711), np.int64(2724), np.int64(3608), np.int64(1617), np.int64(435), np.int64(1869), np.int64(952), np.int64(5764), np.int64(2359), np.int64(6124), np.int64(1389), np.int64(6543), np.int64(280), np.int64(1672), np.int64(4784), np.int64(6484), np.int64(6162), np.int64(1473), np.int64(253), np.int64(1504), np.int64(5924), np.int64(3872), np.int64(4458), np.int64(5683), np.int64(249), np.int64(4197), np.int64(3145), np.int64(4918), np.int64(5527), np.int64(4573), np.int64(5718), np.int64(2438), np.int64(5524), np.int64(118), np.int64(2852), np.int64(7581), np.int64(1228), np.int64(4747), np.int64(627), np.int64(4441), np.int64(7216), np.int64(1571), np.int64(2027), np.int64(6419), np.int64(130), np.int64(2999), np.int64(648), np.int64(1363), np.int64(6917), np.int64(2308), np.int64(7302), np.int64(7699), np.int64(5367), np.int64(234), np.int64(428), np.int64(824), np.int64(3744), np.int64(2815), np.int64(752), np.int64(2816), np.int64(1638), np.int64(1077), np.int64(3424), np.int64(4085), np.int64(3167), np.int64(2565), np.int64(4064), np.int64(572), np.int64(664), np.int64(2248), np.int64(6874), np.int64(3211), np.int64(2966), np.int64(4238), np.int64(6452), np.int64(6076), np.int64(338), np.int64(2868), np.int64(2806), np.int64(2904), np.int64(597), np.int64(2329), np.int64(5639), np.int64(4143), np.int64(4386), np.int64(2869), np.int64(3773), np.int64(2790), np.int64(4522), np.int64(5072), np.int64(4756), np.int64(5755), np.int64(6390), np.int64(1412), np.int64(7134), np.int64(5497), np.int64(1776), np.int64(1554), np.int64(4855), np.int64(5934), np.int64(7726), np.int64(6757), np.int64(5120), np.int64(1920), np.int64(6593), np.int64(1247), np.int64(720), np.int64(4457), np.int64(6301), np.int64(1856), np.int64(2468), np.int64(6796), np.int64(5046), np.int64(1276), np.int64(5105), np.int64(6202), np.int64(6180), np.int64(5906), np.int64(6393), np.int64(7612), np.int64(2175), np.int64(7470), np.int64(3128), np.int64(3936), np.int64(2368), np.int64(2947), np.int64(754), np.int64(6029), np.int64(6764), np.int64(7226), np.int64(7841), np.int64(2036), np.int64(2840), np.int64(273), np.int64(3179), np.int64(4372), np.int64(7185), np.int64(516), np.int64(5320), np.int64(3674), np.int64(4233), np.int64(2693), np.int64(5295), np.int64(3182), np.int64(5897), np.int64(5678), np.int64(254), np.int64(3262), np.int64(1778), np.int64(645), np.int64(5427), np.int64(2249), np.int64(5000), np.int64(7656), np.int64(3249), np.int64(2060), np.int64(7815), np.int64(3557), np.int64(3080), np.int64(300), np.int64(554), np.int64(2114), np.int64(4838), np.int64(4239), np.int64(1977), np.int64(6134), np.int64(3607), np.int64(1942), np.int64(53), np.int64(6810), np.int64(7176), np.int64(6544), np.int64(4769), np.int64(5865), np.int64(7077), np.int64(5019), np.int64(3112), np.int64(7460), np.int64(6876), np.int64(6541), np.int64(5745), np.int64(4237), np.int64(4111), np.int64(743), np.int64(2269), np.int64(4470), np.int64(4081), np.int64(4210), np.int64(5589), np.int64(6903), np.int64(6361), np.int64(7137), np.int64(6549), np.int64(3895), np.int64(5861), np.int64(3477), np.int64(2625), np.int64(4601), np.int64(2323), np.int64(2701), np.int64(5054), np.int64(7441), np.int64(804), np.int64(6734), np.int64(569), np.int64(6635), np.int64(903), np.int64(3386), np.int64(3565), np.int64(4999), np.int64(7807), np.int64(2252), np.int64(2334), np.int64(7158), np.int64(6337), np.int64(517), np.int64(3734), np.int64(6535), np.int64(3428), np.int64(7253), np.int64(2065), np.int64(6253), np.int64(6364), np.int64(4421), np.int64(2075), np.int64(3810), np.int64(4554), np.int64(6717), np.int64(1988), np.int64(168), np.int64(5229), np.int64(595), np.int64(3826), np.int64(1331), np.int64(3833), np.int64(1578), np.int64(6272), np.int64(3974), np.int64(2667), np.int64(4544), np.int64(6224), np.int64(6941), np.int64(5286), np.int64(687), np.int64(3631), np.int64(7823), np.int64(1890), np.int64(1099), np.int64(2287), np.int64(6821), np.int64(5411), np.int64(2956), np.int64(6857), np.int64(2814), np.int64(738), np.int64(419), np.int64(7067), np.int64(6466), np.int64(6421), np.int64(1403), np.int64(3938), np.int64(568), np.int64(7723), np.int64(497), np.int64(1524), np.int64(5306), np.int64(2572), np.int64(4181), np.int64(5929), np.int64(6504), np.int64(1769), np.int64(7095), np.int64(2796), np.int64(4827), np.int64(2246), np.int64(7806), np.int64(6698), np.int64(1189), np.int64(7192), np.int64(3473), np.int64(4706), np.int64(817), np.int64(3517), np.int64(6283), np.int64(1673), np.int64(7769), np.int64(4849), np.int64(3129), np.int64(4176), np.int64(3174), np.int64(2055), np.int64(3730), np.int64(5573), np.int64(7014), np.int64(6665), np.int64(110), np.int64(1711), np.int64(2738), np.int64(1780), np.int64(7695), np.int64(193), np.int64(1951), np.int64(5239), np.int64(3422), np.int64(2280), np.int64(7232), np.int64(4112), np.int64(4995), np.int64(5469), np.int64(7339), np.int64(408), np.int64(7194), np.int64(5474), np.int64(9), np.int64(4462), np.int64(3071), np.int64(2410), np.int64(3020), np.int64(4751), np.int64(3547), np.int64(6461), np.int64(7099), np.int64(6004), np.int64(6782), np.int64(2369), np.int64(7463), np.int64(1215), np.int64(4792), np.int64(3255), np.int64(2654), np.int64(7087), np.int64(7389), np.int64(4054), np.int64(2099), np.int64(6438), np.int64(3745), np.int64(6492), np.int64(331), np.int64(6128), np.int64(5176), np.int64(5679), np.int64(5575), np.int64(4161), np.int64(1676), np.int64(3117), np.int64(665), np.int64(3306), np.int64(600), np.int64(7693), np.int64(7172), np.int64(4797), np.int64(1130), np.int64(5784), np.int64(5436), np.int64(7489), np.int64(3863), np.int64(6794), np.int64(1489), np.int64(6683), np.int64(5042), np.int64(7141), np.int64(6669), np.int64(1703), np.int64(24), np.int64(2524), np.int64(783), np.int64(3884), np.int64(6446), np.int64(4545), np.int64(5557), np.int64(244), np.int64(5219), np.int64(7386), np.int64(565), np.int64(6508), np.int64(4640), np.int64(570), np.int64(557), np.int64(7322), np.int64(7622), np.int64(7084), np.int64(892), np.int64(4611), np.int64(957), np.int64(3), np.int64(765), np.int64(4403), np.int64(749), np.int64(7256), np.int64(7058), np.int64(84), np.int64(4073), np.int64(6624), np.int64(5335), np.int64(7396), np.int64(3038), np.int64(5808), np.int64(3172), np.int64(3188), np.int64(2318), np.int64(4319), np.int64(2458), np.int64(5060), np.int64(7299), np.int64(3909), np.int64(7744), np.int64(7051), np.int64(4740), np.int64(2706), np.int64(930), np.int64(4193), np.int64(7309), np.int64(6297), np.int64(1950), np.int64(6789), np.int64(346), np.int64(4256), np.int64(6958), np.int64(1786), np.int64(2453), np.int64(1052), np.int64(6839), np.int64(464), np.int64(7582), np.int64(36), np.int64(3562), np.int64(2389), np.int64(7240), np.int64(672), np.int64(5181), np.int64(5361), np.int64(220), np.int64(6048), np.int64(4352), np.int64(5787), np.int64(4384), np.int64(6806), np.int64(6640), np.int64(2447), np.int64(4131), np.int64(4231), np.int64(6501), np.int64(2159), np.int64(791), np.int64(3218), np.int64(2808), np.int64(4843), np.int64(6225), np.int64(223), np.int64(5362), np.int64(3480), np.int64(2069), np.int64(7002), np.int64(730), np.int64(474), np.int64(3688), np.int64(6248), np.int64(1101), np.int64(7059), np.int64(7472), np.int64(898), np.int64(4152), np.int64(3751), np.int64(328), np.int64(3686), np.int64(5899), np.int64(662), np.int64(7487), np.int64(5579), np.int64(1332), np.int64(7741), np.int64(5371), np.int64(1023), np.int64(1817), np.int64(5610), np.int64(6465), np.int64(1431), np.int64(7355), np.int64(329), np.int64(436), np.int64(149), np.int64(3812), np.int64(7501), np.int64(405), np.int64(7425), np.int64(6209), np.int64(2402), np.int64(3687), np.int64(2887), np.int64(7743), np.int64(750), np.int64(3085), np.int64(2198), np.int64(1570), np.int64(7261), np.int64(4169), np.int64(3531), np.int64(1854), np.int64(2045), np.int64(3668), np.int64(424), np.int64(4314), np.int64(5152), np.int64(2), np.int64(3315), np.int64(4851), np.int64(3655), np.int64(4518), np.int64(4664), np.int64(7285), np.int64(3929), np.int64(4787), np.int64(7273), np.int64(3666), np.int64(7138), np.int64(1557), np.int64(1036), np.int64(7636), np.int64(6962), np.int64(5652), np.int64(2975), np.int64(6580), np.int64(1606), np.int64(5014), np.int64(3919), np.int64(928), np.int64(5816), np.int64(5099), np.int64(5013), np.int64(61), np.int64(7196), np.int64(1364), np.int64(3109), np.int64(4080), np.int64(7060), np.int64(531), np.int64(333), np.int64(4257), np.int64(3025), np.int64(2964), np.int64(6274), np.int64(888), np.int64(2948), np.int64(7756), np.int64(1467), np.int64(7399), np.int64(2930), np.int64(5277), np.int64(5817), np.int64(2591), np.int64(3982), np.int64(3347), np.int64(1527), np.int64(3581), np.int64(3556), np.int64(2939), np.int64(7670), np.int64(6332), np.int64(28), np.int64(931), np.int64(6675), np.int64(6845), np.int64(4061), np.int64(7163), np.int64(2168), np.int64(4984), np.int64(6355), np.int64(6804), np.int64(977), np.int64(840), np.int64(560), np.int64(1133), np.int64(5038), np.int64(3258), np.int64(81), np.int64(2909), np.int64(7071), np.int64(6621), np.int64(1562), np.int64(4452), np.int64(101), np.int64(4941), np.int64(3877), np.int64(6060), np.int64(5139), np.int64(6990), np.int64(4656), np.int64(2002), np.int64(6944), np.int64(2889), np.int64(5670), np.int64(1712), np.int64(5011), np.int64(1843), np.int64(5811), np.int64(5467), np.int64(6159), np.int64(6340), np.int64(2439), np.int64(1585), np.int64(6231), np.int64(2288), np.int64(2996), np.int64(5803), np.int64(7839), np.int64(1625), np.int64(3824), np.int64(3499), np.int64(2608), np.int64(6265), np.int64(1568), np.int64(306), np.int64(372), np.int64(2430), np.int64(5149), np.int64(3346), np.int64(1777), np.int64(1757), np.int64(1883), np.int64(3433), np.int64(403), np.int64(476), np.int64(5292), np.int64(7128), np.int64(5245), np.int64(5001), np.int64(4431), np.int64(6205), np.int64(1846), np.int64(1653), np.int64(6166), np.int64(3857), np.int64(2049), np.int64(4363), np.int64(1369), np.int64(6487), np.int64(5343), np.int64(4297), np.int64(916), np.int64(3253), np.int64(312), np.int64(441), np.int64(4742), np.int64(1968), np.int64(6860), np.int64(6881), np.int64(2510), np.int64(3289), np.int64(5549), np.int64(5313), np.int64(3718), np.int64(6033), np.int64(7637), np.int64(2090), np.int64(7197), np.int64(5221), np.int64(1180), np.int64(2463), np.int64(2936), np.int64(4255), np.int64(1888), np.int64(3662), np.int64(1001), np.int64(7505), np.int64(757), np.int64(2483), np.int64(3754), np.int64(2573), np.int64(1321), np.int64(1675), np.int64(3438), np.int64(7558), np.int64(7280), np.int64(1324), np.int64(6853), np.int64(6171), np.int64(1492), np.int64(1256), np.int64(3791), np.int64(3873), np.int64(1576), np.int64(88), np.int64(1365), np.int64(2908), np.int64(3848), np.int64(7803), np.int64(1746), np.int64(107), np.int64(2567), np.int64(4622), np.int64(1302), np.int64(4014), np.int64(3503), np.int64(6815), np.int64(7702), np.int64(4466), np.int64(3146), np.int64(2276), np.int64(2519), np.int64(7203), np.int64(2931), np.int64(5952), np.int64(6820), np.int64(7508), np.int64(3731), np.int64(4510), np.int64(1441), np.int64(2355), np.int64(2759), np.int64(4449), np.int64(5881), np.int64(2371), np.int64(231), np.int64(5900), np.int64(87), np.int64(4191), np.int64(6114), np.int64(3304), np.int64(6238), np.int64(1157), np.int64(3893), np.int64(1192), np.int64(7320), np.int64(1589), np.int64(1378), np.int64(7432), np.int64(4019), np.int64(2554), np.int64(5738), np.int64(3679), np.int64(19), np.int64(5155), np.int64(6059), np.int64(583), np.int64(4420), np.int64(7481), np.int64(1066), np.int64(3540), np.int64(1507), np.int64(3354), np.int64(2152), np.int64(4109), np.int64(1220), np.int64(4929), np.int64(4268), np.int64(1384), np.int64(5455), np.int64(7365), np.int64(7553), np.int64(3457), np.int64(5355), np.int64(1414), np.int64(889), np.int64(3728), np.int64(3336), np.int64(6110), np.int64(2264), np.int64(4580), np.int64(5807), np.int64(1895), np.int64(1428), np.int64(2954), np.int64(1787), np.int64(5416), np.int64(1958), np.int64(2138), np.int64(1423), np.int64(1759), np.int64(5868), np.int64(3463), np.int64(5994), np.int64(6406), np.int64(6111), np.int64(5496), np.int64(3193), np.int64(6084), np.int64(4434), np.int64(6199), np.int64(6731), np.int64(6321), np.int64(5668), np.int64(7478), np.int64(2564), np.int64(4187), np.int64(2357), np.int64(2150), np.int64(6940), np.int64(3502), np.int64(6739), np.int64(5171), np.int64(3031), np.int64(2787), np.int64(1836), np.int64(1873), np.int64(4096), np.int64(4882), np.int64(4362), np.int64(6528), np.int64(47), np.int64(866), np.int64(1006), np.int64(5164), np.int64(5750), np.int64(1940), np.int64(6141), np.int64(2569), np.int64(3883), np.int64(6294), np.int64(3051), np.int64(5694), np.int64(7281), np.int64(7252), np.int64(5278), np.int64(426), np.int64(3399), np.int64(2769), np.int64(11), np.int64(6178), np.int64(1996), np.int64(5080), np.int64(7204), np.int64(555), np.int64(3267), np.int64(2182), np.int64(5661), np.int64(2702), np.int64(3200), np.int64(3212), np.int64(3027), np.int64(5944), np.int64(5815), np.int64(5298), np.int64(6875), np.int64(3283), np.int64(6638), np.int64(7655), np.int64(2849), np.int64(4613), np.int64(1194), np.int64(417), np.int64(1597), np.int64(3634), np.int64(764), np.int64(4270), np.int64(1383), np.int64(5848), np.int64(345), np.int64(6314), np.int64(173), np.int64(6763), np.int64(7142), np.int64(2775), np.int64(6527), np.int64(4139), np.int64(3016), np.int64(5707), np.int64(1406), np.int64(4780), np.int64(989), np.int64(1748), np.int64(7346), np.int64(5517), np.int64(6271), np.int64(3437), np.int64(2457), np.int64(2800), np.int64(4395), np.int64(513), np.int64(92), np.int64(3013), np.int64(5137), np.int64(1300), np.int64(786), np.int64(3456), np.int64(1848), np.int64(141), np.int64(6247), np.int64(7770), np.int64(7779), np.int64(988), np.int64(429), np.int64(5314), np.int64(1864), np.int64(550), np.int64(2469), np.int64(4543), np.int64(3951), np.int64(140), np.int64(2343), np.int64(6615), np.int64(380), np.int64(3197), np.int64(2978), np.int64(5785), np.int64(671), np.int64(7148), np.int64(1145), np.int64(6315), np.int64(785), np.int64(830), np.int64(6261), np.int64(1680), np.int64(7466), np.int64(7357), np.int64(5184), np.int64(669), np.int64(7525), np.int64(6212), np.int64(2801), np.int64(4050), np.int64(7173), np.int64(2562), np.int64(5841), np.int64(2633), np.int64(711), np.int64(1086), np.int64(6389), np.int64(1812), np.int64(6062), np.int64(6901), np.int64(2837), np.int64(7674), np.int64(4938), np.int64(6240), np.int64(2920), np.int64(1415), np.int64(4166), np.int64(7406), np.int64(7682), np.int64(6211), np.int64(7451), np.int64(1344), np.int64(4123), np.int64(1495), np.int64(7356), np.int64(4259), np.int64(5378), np.int64(2351), np.int64(353), np.int64(3227), np.int64(6498), np.int64(7516), np.int64(3181), np.int64(3725), np.int64(1543), np.int64(868), np.int64(5713), np.int64(3561), np.int64(5103), np.int64(5618), np.int64(1861), np.int64(5089), np.int64(2416), np.int64(1642), np.int64(6659), np.int64(5662), np.int64(5754), np.int64(2244), np.int64(6566), np.int64(3201), np.int64(1667), np.int64(4116), np.int64(5075), np.int64(1057), np.int64(4012), np.int64(4056), np.int64(6582), np.int64(4220), np.int64(1697), np.int64(519), np.int64(5127), np.int64(2302), np.int64(2611), np.int64(4758), np.int64(5818), np.int64(6127), np.int64(2993), np.int64(6495), np.int64(7791), np.int64(1948), np.int64(1455), np.int64(5799), np.int64(7810), np.int64(4861), np.int64(3374), np.int64(1283), np.int64(5857), np.int64(4448), np.int64(3551), np.int64(1207), np.int64(1790), np.int64(6216), np.int64(3994), np.int64(3278), np.int64(6266), np.int64(6584), np.int64(6000), np.int64(5357), np.int64(5479), np.int64(7584), np.int64(1536), np.int64(317), np.int64(6071), np.int64(2953), np.int64(7283), np.int64(7496), np.int64(3095), np.int64(6623), np.int64(2208), np.int64(2273), np.int64(6206), np.int64(5056), np.int64(959), np.int64(7000), np.int64(7078), np.int64(5926), np.int64(3467), np.int64(1083), np.int64(7305), np.int64(5285), np.int64(7754), np.int64(6824), np.int64(4945), np.int64(7498), np.int64(2726), np.int64(4626), np.int64(7689), np.int64(6052), np.int64(2265), np.int64(2615), np.int64(1541), np.int64(1641), np.int64(1902), np.int64(1727), np.int64(4328), np.int64(6799), np.int64(4530), np.int64(1825), np.int64(1240), np.int64(6040), np.int64(7390), np.int64(5721), np.int64(3755), np.int64(5475), np.int64(1619), np.int64(5288), np.int64(4655), np.int64(708), np.int64(2518), np.int64(4549), np.int64(5572), np.int64(974), np.int64(6239), np.int64(5040), np.int64(1368), np.int64(1288), np.int64(2112), np.int64(7347), np.int64(3019), np.int64(2070), np.int64(255), np.int64(634), np.int64(4367), np.int64(7805), np.int64(3996), np.int64(793), np.int64(1487), np.int64(4357), np.int64(5364), np.int64(3880), np.int64(7486), np.int64(7531), np.int64(2024), np.int64(7488), np.int64(6410), np.int64(7290), np.int64(138), np.int64(6456), np.int64(2328), np.int64(2641), np.int64(183), np.int64(739), np.int64(1726), np.int64(5824), np.int64(1832), np.int64(2665), np.int64(2459), np.int64(5717), np.int64(2261), np.int64(4846), np.int64(251), np.int64(5051), np.int64(5460), np.int64(910), np.int64(1184), np.int64(2788), np.int64(2760), np.int64(2750), np.int64(6351), np.int64(6316), np.int64(4654), np.int64(3638), np.int64(3273), np.int64(2674), np.int64(7045), np.int64(1922), np.int64(7272), np.int64(438), np.int64(1246), np.int64(7106), np.int64(3552), np.int64(5751), np.int64(2394), np.int64(3101), np.int64(4848), np.int64(5977), np.int64(5257), np.int64(4473), np.int64(5267), np.int64(6304), np.int64(6982), np.int64(5782), np.int64(7092), np.int64(6210), np.int64(6422), np.int64(4098), np.int64(5595), np.int64(7202), np.int64(4136), np.int64(4685), np.int64(4491), np.int64(4125), np.int64(3635), np.int64(5590), np.int64(3159), np.int64(760), np.int64(4020), np.int64(3300), np.int64(2925), np.int64(1319), np.int64(3790), np.int64(2199), np.int64(2942), np.int64(1964), np.int64(2218), np.int64(4952), np.int64(1394), np.int64(3161), np.int64(1169)]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "test_id = []\n",
    "\n",
    "for i in range(len(test_paths)):\n",
    "    try:\n",
    "        # open image\n",
    "        image = Image.open(f\"Data/test/{test_paths.iloc[i]}\")\n",
    "        # resize image to (50, 50)\n",
    "        image = image.resize(rescale_size)\n",
    "        image = np.array(image)\n",
    "        test_data.append(image)\n",
    "        test_id.append(test_index.iloc[i])\n",
    "    except:\n",
    "        print(f\"error loading image {test_paths.iloc[i]}\")\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict classes of test data\n",
    "with tf.device('/GPU:0'):\n",
    "    pred = np.argmax(model.predict(test_data), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42c35519",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'id': test_index, 'ClassId': pred})\n",
    "result.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2acb2",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6e9f2",
   "metadata": {},
   "source": [
    "### LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b553d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rayzh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "r = 1\n",
    "points = r * 8\n",
    "method = 'uniform'\n",
    "\n",
    "def extract_lbp(source: str):\n",
    "    # extract image paths\n",
    "\n",
    "    if source == \"train\":\n",
    "        all_images = train_metadata[\"image_path\"]\n",
    "    else:\n",
    "        all_images = test_metadata[\"image_path\"]\n",
    "    \n",
    "    lbp_data = []\n",
    "    lbp_images = []\n",
    "\n",
    "    # extract lbp values\n",
    "    for path in all_images:\n",
    "        image = Image.open(f\"Data/{source}/{path}\")\n",
    "        image = image.resize(rescale_size)\n",
    "        gray_image = color.rgb2gray(image)\n",
    "\n",
    "        lbp = local_binary_pattern(gray_image, points, r, method)\n",
    "\n",
    "        n_bins = int(lbp.max() + 1)\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "\n",
    "        lbp_data.append(hist)\n",
    "        lbp_images.append(path)\n",
    "\n",
    "\n",
    "    lbp = pd.DataFrame(lbp_data)\n",
    "    lbp.insert(0, 'image_path', lbp_images)\n",
    "    \n",
    "    if source == \"train\":\n",
    "        lbp.index = train_metadata.index\n",
    "    else:\n",
    "        lbp.index = test_metadata.index\n",
    "\n",
    "    lbp.to_csv('lbp.csv', index=False)\n",
    "\n",
    "    return lbp\n",
    "\n",
    "lbp_train = extract_lbp(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b15fd",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55218f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "SIGMA = 1\n",
    "\n",
    "def extract_canny(source: str):\n",
    "    if source == \"train\":\n",
    "        all_images = train_metadata[\"image_path\"]\n",
    "    else:\n",
    "        all_images = test_metadata[\"image_path\"]\n",
    "\n",
    "    canny_data = []\n",
    "    canny_images = []\n",
    "\n",
    "    for path in all_images:\n",
    "        image = Image.open(f\"Data/{source}/{path}\")\n",
    "        image = image.resize(rescale_size)\n",
    "        image_array = np.array(image)\n",
    "        gray_image = color.rgb2gray(image_array)\n",
    "\n",
    "        edges = canny(gray_image, sigma=SIGMA)\n",
    "\n",
    "        canny_data.append(edges.astype(np.float32)) \n",
    "        canny_images.append(path)\n",
    "\n",
    "    canny_flat = [edge.flatten() for edge in canny_data]\n",
    "    canny_flat = pd.DataFrame(canny_flat)\n",
    "    canny_flat.insert(0, 'image_path', canny_images)\n",
    "    \n",
    "    if source == \"train\":\n",
    "        canny_flat.index = train_metadata.index\n",
    "    else:\n",
    "        canny_flat.index = test_metadata.index\n",
    "\n",
    "    if False:\n",
    "        canny_entropy(canny_data)\n",
    "\n",
    "    # for i in range(3):\n",
    "    #     plt.imshow(canny_data[i], cmap='gray')\n",
    "    #     plt.title(f\"Canny output {i}\")\n",
    "    #     plt.axis('off')\n",
    "    #     plt.show()    \n",
    "\n",
    "    return canny_flat\n",
    "\n",
    "canny_train = extract_canny(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab4c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning the value of sigma using entropy\n",
    "\n",
    "def canny_entropy(canny_data):\n",
    "    entropies = []\n",
    "\n",
    "    for data in canny_data:\n",
    "        values, counts = np.unique(data.astype(int), return_counts=True)\n",
    "        probs = counts / counts.sum() \n",
    "        entropies.append(float(entropy(probs, base=2)))\n",
    "\n",
    "    print(np.mean(entropies)) \n",
    "    # sigma = 1: 0.5726\n",
    "    # sigma = 2: 0.3871\n",
    "    # sigma = 3: 0.2597\n",
    "\n",
    "    # choose sigma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2353, 2500)\n",
      "Reduced shape: (2353, 458)\n"
     ]
    }
   ],
   "source": [
    "X = canny_train.drop(columns=['image_path']).values  \n",
    "\n",
    "pca = PCA(n_components=0.75)  # reduce dimensions but keep 75% of the variance\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Reduced shape: {X_pca.shape}\")\n",
    "\n",
    "canny_df = pd.DataFrame(X_pca, index=canny_train.index)\n",
    "\n",
    "# Add the image_path column back\n",
    "canny_df.insert(0, 'image_path', canny_train['image_path'])\n",
    "\n",
    "canny_df.to_csv('canny.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056b18b",
   "metadata": {},
   "source": [
    "### Sobel Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b0876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sobel(source: str):\n",
    "\n",
    "    if source == \"train\":\n",
    "        all_images = train_metadata[\"image_path\"]\n",
    "    else:\n",
    "        all_images = test_metadata[\"image_path\"]\n",
    "    \n",
    "    sobel_data = []\n",
    "    sobel_images = []\n",
    "\n",
    "    for path in all_images:\n",
    "        image = Image.open(f\"Data/{source}/{path}\")\n",
    "        image = image.resize(rescale_size)\n",
    "        image_array = np.array(image)\n",
    "        gray_image = color.rgb2gray(image_array)\n",
    "\n",
    "        sobel_edge = sobel(gray_image)\n",
    "\n",
    "        # sx = sobel_h(gray_image)\n",
    "        # sy = sobel_v(gray_image)\n",
    "        # sobel_edge = np.hypot(sx, sy)\n",
    "\n",
    "        sobel_data.append(sobel_edge.flatten())\n",
    "        sobel_images.append(path)\n",
    "\n",
    "    sobel_df = pd.DataFrame(sobel_data)\n",
    "    sobel_df.insert(0, 'image_path', sobel_images)\n",
    "    \n",
    "    if source == \"train\":\n",
    "        sobel_df.index = train_metadata.index\n",
    "    else:\n",
    "        sobel_df.index = test_metadata.index\n",
    "\n",
    "    # for i in range(3):\n",
    "    #     sobel_image = sobel_df.iloc[i].values.reshape(rescale_size)\n",
    "    #     plt.imshow(sobel_image, cmap='gray')\n",
    "    #     plt.title(f\"Sobel output {i}\")\n",
    "    #     plt.axis('off')\n",
    "    #     plt.show()\n",
    "\n",
    "    return sobel_df\n",
    "\n",
    "sobel_train = extract_sobel(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00a32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2353, 2500)\n",
      "Reduced shape: (2353, 101)\n"
     ]
    }
   ],
   "source": [
    "X = sobel_train.drop(columns=[\"image_path\"]).values  \n",
    "\n",
    "pca = PCA(n_components=0.75)  \n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Reduced shape: {X_pca.shape}\")\n",
    "\n",
    "sobel_df = pd.DataFrame(X_pca, index=sobel_train.index)\n",
    "sobel_df.insert(0, 'image_path', sobel_train[\"image_path\"])\n",
    "\n",
    "sobel_df.to_csv('sobel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60d1b2",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8200bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_add_features = pd.read_csv(\"Data/train/Features/additional_features.csv\").drop(columns=['image_path'])\n",
    "train_edge_density = train_add_features[[\"edge_density\"]]\n",
    "train_mean_rgb = train_add_features.drop(columns=[\"edge_density\"])\n",
    "train_canny = pd.read_csv(\"Data/train/Features/canny.csv\").drop(columns=['image_path'])\n",
    "train_color_hist = pd.read_csv(\"Data/train/Features/color_histogram.csv\").drop(columns=['image_path'])\n",
    "train_hog_pca = pd.read_csv(\"Data/train/Features/hog_pca.csv\").drop(columns=['image_path'])\n",
    "train_lbp = pd.read_csv(\"Data/train/Features/lbp.csv\").drop(columns=['image_path'])\n",
    "train_sobel = pd.read_csv(\"Data/train/Features/sobel.csv\").drop(columns=['image_path'])\n",
    "\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "train_edge_density_scaled = scaler1.fit_transform(train_edge_density)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "train_mean_rgb_scaled = scaler2.fit_transform(train_mean_rgb)\n",
    "\n",
    "scaler3 = StandardScaler()\n",
    "train_canny_scaled = scaler3.fit_transform(train_canny)\n",
    "\n",
    "scaler4 = StandardScaler()\n",
    "train_color_hist_scaled = scaler4.fit_transform(train_color_hist)\n",
    "\n",
    "scaler5 = StandardScaler()\n",
    "train_hog_pca_scaled = scaler5.fit_transform(train_hog_pca)\n",
    "\n",
    "scaler6 = StandardScaler()\n",
    "train_lbp_scaled = scaler6.fit_transform(train_lbp)\n",
    "\n",
    "scaler7 = StandardScaler()\n",
    "train_sobel_scaled = scaler7.fit_transform(train_sobel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049e2cc",
   "metadata": {},
   "source": [
    "## Training SVM on canny and color hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83e49f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_train = extract_canny(\"train\")\n",
    "train_color_hist = pd.read_csv(\"Data/train/Features/color_histogram.csv\")\n",
    "train_color_hist.index = train_metadata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb5b7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEGREE = 1000\n",
    "pca = PCA(n_components = DEGREE)\n",
    "\n",
    "\n",
    "def apply_pca(data):\n",
    "\n",
    "    X = data.drop(columns=[\"image_path\"])\n",
    "\n",
    "    data_pca = pca.fit_transform(X)\n",
    "    data_pca = pd.DataFrame(data_pca, index=data.index)\n",
    "    data_pca.insert(0, 'image_path', data['image_path'])\n",
    "\n",
    "    return data_pca\n",
    "\n",
    "canny_train_pca = apply_pca(canny_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d91d51f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>ch_86</th>\n",
       "      <th>ch_87</th>\n",
       "      <th>ch_88</th>\n",
       "      <th>ch_89</th>\n",
       "      <th>ch_90</th>\n",
       "      <th>ch_91</th>\n",
       "      <th>ch_92</th>\n",
       "      <th>ch_93</th>\n",
       "      <th>ch_94</th>\n",
       "      <th>ch_95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>-2.051437</td>\n",
       "      <td>-0.669757</td>\n",
       "      <td>-0.315596</td>\n",
       "      <td>0.801923</td>\n",
       "      <td>-0.853103</td>\n",
       "      <td>0.463098</td>\n",
       "      <td>-0.606504</td>\n",
       "      <td>0.774105</td>\n",
       "      <td>0.931920</td>\n",
       "      <td>-0.480700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>-2.525180</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>-0.416241</td>\n",
       "      <td>-1.058156</td>\n",
       "      <td>-0.676034</td>\n",
       "      <td>0.897606</td>\n",
       "      <td>1.331595</td>\n",
       "      <td>1.021448</td>\n",
       "      <td>0.557510</td>\n",
       "      <td>1.062243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>2.291903</td>\n",
       "      <td>-0.143319</td>\n",
       "      <td>2.981271</td>\n",
       "      <td>-0.610320</td>\n",
       "      <td>1.993576</td>\n",
       "      <td>4.577984</td>\n",
       "      <td>-2.032192</td>\n",
       "      <td>2.292870</td>\n",
       "      <td>0.467942</td>\n",
       "      <td>0.524660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062342</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.049874</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.061303</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.082084</td>\n",
       "      <td>0.110137</td>\n",
       "      <td>0.156894</td>\n",
       "      <td>0.670176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>-1.399055</td>\n",
       "      <td>4.003945</td>\n",
       "      <td>-0.877522</td>\n",
       "      <td>-1.250140</td>\n",
       "      <td>1.936476</td>\n",
       "      <td>0.971122</td>\n",
       "      <td>-0.085330</td>\n",
       "      <td>-0.685970</td>\n",
       "      <td>-0.353868</td>\n",
       "      <td>0.193804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>0.134350</td>\n",
       "      <td>1.608424</td>\n",
       "      <td>1.234319</td>\n",
       "      <td>-1.729691</td>\n",
       "      <td>0.694583</td>\n",
       "      <td>-3.498270</td>\n",
       "      <td>1.538762</td>\n",
       "      <td>2.223016</td>\n",
       "      <td>0.389273</td>\n",
       "      <td>0.170613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.014988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-0.835904</td>\n",
       "      <td>-0.338931</td>\n",
       "      <td>0.450743</td>\n",
       "      <td>-0.228883</td>\n",
       "      <td>-0.453278</td>\n",
       "      <td>0.557945</td>\n",
       "      <td>2.058186</td>\n",
       "      <td>0.317780</td>\n",
       "      <td>0.399139</td>\n",
       "      <td>-1.141895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010370</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.025580</td>\n",
       "      <td>0.021432</td>\n",
       "      <td>0.047013</td>\n",
       "      <td>0.070519</td>\n",
       "      <td>0.105087</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.763265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>0.767188</td>\n",
       "      <td>1.727126</td>\n",
       "      <td>3.389711</td>\n",
       "      <td>1.114812</td>\n",
       "      <td>2.352844</td>\n",
       "      <td>1.234217</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>-1.399358</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>-1.250483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240318</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>0.034855</td>\n",
       "      <td>0.012230</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.201182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>7.668096</td>\n",
       "      <td>-2.868917</td>\n",
       "      <td>5.046779</td>\n",
       "      <td>2.300111</td>\n",
       "      <td>3.725677</td>\n",
       "      <td>-2.759581</td>\n",
       "      <td>4.649038</td>\n",
       "      <td>-1.302922</td>\n",
       "      <td>-0.842877</td>\n",
       "      <td>3.635046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019605</td>\n",
       "      <td>0.020726</td>\n",
       "      <td>0.030248</td>\n",
       "      <td>0.021286</td>\n",
       "      <td>0.029128</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>0.047613</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.185409</td>\n",
       "      <td>0.949452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>-3.016385</td>\n",
       "      <td>-4.275195</td>\n",
       "      <td>0.433993</td>\n",
       "      <td>-3.314471</td>\n",
       "      <td>-0.823573</td>\n",
       "      <td>2.770625</td>\n",
       "      <td>-2.193447</td>\n",
       "      <td>-3.308840</td>\n",
       "      <td>-1.032386</td>\n",
       "      <td>-0.966145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.052931</td>\n",
       "      <td>0.180739</td>\n",
       "      <td>0.223987</td>\n",
       "      <td>0.229797</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>-2.283719</td>\n",
       "      <td>-1.714166</td>\n",
       "      <td>-1.305149</td>\n",
       "      <td>-1.163707</td>\n",
       "      <td>-0.126064</td>\n",
       "      <td>1.241179</td>\n",
       "      <td>1.242572</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>1.573938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5488 rows × 1096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "id                                                                           \n",
       "7218 -2.051437 -0.669757 -0.315596  0.801923 -0.853103  0.463098 -0.606504   \n",
       "6333 -2.525180  0.028389 -0.416241 -1.058156 -0.676034  0.897606  1.331595   \n",
       "6867  2.291903 -0.143319  2.981271 -0.610320  1.993576  4.577984 -2.032192   \n",
       "7730 -1.399055  4.003945 -0.877522 -1.250140  1.936476  0.971122 -0.085330   \n",
       "6338  0.134350  1.608424  1.234319 -1.729691  0.694583 -3.498270  1.538762   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "456  -0.835904 -0.338931  0.450743 -0.228883 -0.453278  0.557945  2.058186   \n",
       "4084  0.767188  1.727126  3.389711  1.114812  2.352844  1.234217  0.578990   \n",
       "5117  7.668096 -2.868917  5.046779  2.300111  3.725677 -2.759581  4.649038   \n",
       "3334 -3.016385 -4.275195  0.433993 -3.314471 -0.823573  2.770625 -2.193447   \n",
       "2403 -2.283719 -1.714166 -1.305149 -1.163707 -0.126064  1.241179  1.242572   \n",
       "\n",
       "             7         8         9  ...     ch_86     ch_87     ch_88  \\\n",
       "id                                  ...                                 \n",
       "7218  0.774105  0.931920 -0.480700  ...  0.000000  0.000000  0.000000   \n",
       "6333  1.021448  0.557510  1.062243  ...  0.000000  0.000000  0.000000   \n",
       "6867  2.292870  0.467942  0.524660  ...  0.062342  0.056108  0.049874   \n",
       "7730 -0.685970 -0.353868  0.193804  ...  0.000000  0.000000  0.000000   \n",
       "6338  2.223016  0.389273  0.170613  ...  0.013489  0.023231  0.016487   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "456   0.317780  0.399139 -1.141895  ...  0.010370  0.017284  0.019358   \n",
       "4084 -1.399358 -0.018394 -1.250483  ...  0.240318  0.059315  0.034855   \n",
       "5117 -1.302922 -0.842877  3.635046  ...  0.019605  0.020726  0.030248   \n",
       "3334 -3.308840 -1.032386 -0.966145  ...  0.038084  0.052931  0.180739   \n",
       "2403  0.615113  0.545328  1.573938  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "         ch_89     ch_90     ch_91     ch_92     ch_93     ch_94     ch_95  \n",
       "id                                                                          \n",
       "7218  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6333  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6867  0.043639  0.061303  0.072732  0.082084  0.110137  0.156894  0.670176  \n",
       "7730  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6338  0.008243  0.025479  0.023981  0.011241  0.006745  0.006745  0.014988  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "456   0.025580  0.021432  0.047013  0.070519  0.105087  0.152100  0.763265  \n",
       "4084  0.012230  0.008561  0.011007  0.009784  0.010395  0.009784  0.201182  \n",
       "5117  0.021286  0.029128  0.024086  0.047613  0.098026  0.185409  0.949452  \n",
       "3334  0.223987  0.229797  0.016137  0.000000  0.000000  0.000000  0.000000  \n",
       "2403  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5488 rows x 1096 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_canny_color = pd.concat([canny_train_pca, train_color_hist], axis=1)\n",
    "train_canny_color.columns = train_canny_color.columns.astype(str)\n",
    "train_canny_color = train_canny_color.drop(columns=[\"image_path\"])\n",
    "train_canny_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7912c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model = SVC(kernel=\"linear\", C=1.0)\n",
    "rfe = RFE(estimator=SVM_model, n_features_to_select=300, step=50)\n",
    "\n",
    "rfe.fit(train_canny_color, train_metadata[\"ClassId\"])\n",
    "\n",
    "col = rfe.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49d5749c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>ch_37</th>\n",
       "      <th>ch_38</th>\n",
       "      <th>ch_63</th>\n",
       "      <th>ch_64</th>\n",
       "      <th>ch_65</th>\n",
       "      <th>ch_66</th>\n",
       "      <th>ch_67</th>\n",
       "      <th>ch_68</th>\n",
       "      <th>ch_69</th>\n",
       "      <th>ch_70</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>-2.051437</td>\n",
       "      <td>-0.669757</td>\n",
       "      <td>-0.315596</td>\n",
       "      <td>0.801923</td>\n",
       "      <td>0.463098</td>\n",
       "      <td>-0.606504</td>\n",
       "      <td>0.774105</td>\n",
       "      <td>0.931920</td>\n",
       "      <td>-0.480700</td>\n",
       "      <td>2.462802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256266</td>\n",
       "      <td>0.538795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.315108</td>\n",
       "      <td>0.278908</td>\n",
       "      <td>0.401495</td>\n",
       "      <td>0.321690</td>\n",
       "      <td>0.440164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>-2.525180</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>-0.416241</td>\n",
       "      <td>-1.058156</td>\n",
       "      <td>0.897606</td>\n",
       "      <td>1.331595</td>\n",
       "      <td>1.021448</td>\n",
       "      <td>0.557510</td>\n",
       "      <td>1.062243</td>\n",
       "      <td>0.484856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398772</td>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081961</td>\n",
       "      <td>0.297379</td>\n",
       "      <td>0.517149</td>\n",
       "      <td>0.529480</td>\n",
       "      <td>0.393846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>2.291903</td>\n",
       "      <td>-0.143319</td>\n",
       "      <td>2.981271</td>\n",
       "      <td>-0.610320</td>\n",
       "      <td>4.577984</td>\n",
       "      <td>-2.032192</td>\n",
       "      <td>2.292870</td>\n",
       "      <td>0.467942</td>\n",
       "      <td>0.524660</td>\n",
       "      <td>-0.777841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217631</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>0.233436</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.269109</td>\n",
       "      <td>0.215080</td>\n",
       "      <td>0.098708</td>\n",
       "      <td>0.087279</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>0.217158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>-1.399055</td>\n",
       "      <td>4.003945</td>\n",
       "      <td>-0.877522</td>\n",
       "      <td>-1.250140</td>\n",
       "      <td>0.971122</td>\n",
       "      <td>-0.085330</td>\n",
       "      <td>-0.685970</td>\n",
       "      <td>-0.353868</td>\n",
       "      <td>0.193804</td>\n",
       "      <td>-0.917611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084188</td>\n",
       "      <td>0.047046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474292</td>\n",
       "      <td>0.781341</td>\n",
       "      <td>0.108681</td>\n",
       "      <td>0.192038</td>\n",
       "      <td>0.305995</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>0.134350</td>\n",
       "      <td>1.608424</td>\n",
       "      <td>1.234319</td>\n",
       "      <td>-1.729691</td>\n",
       "      <td>-3.498270</td>\n",
       "      <td>1.538762</td>\n",
       "      <td>2.223016</td>\n",
       "      <td>0.389273</td>\n",
       "      <td>0.170613</td>\n",
       "      <td>5.642231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.211330</td>\n",
       "      <td>0.172361</td>\n",
       "      <td>0.194843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-0.835904</td>\n",
       "      <td>-0.338931</td>\n",
       "      <td>0.450743</td>\n",
       "      <td>-0.228883</td>\n",
       "      <td>0.557945</td>\n",
       "      <td>2.058186</td>\n",
       "      <td>0.317780</td>\n",
       "      <td>0.399139</td>\n",
       "      <td>-1.141895</td>\n",
       "      <td>2.118095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.378768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.178372</td>\n",
       "      <td>0.101630</td>\n",
       "      <td>0.273780</td>\n",
       "      <td>0.250273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>0.767188</td>\n",
       "      <td>1.727126</td>\n",
       "      <td>3.389711</td>\n",
       "      <td>1.114812</td>\n",
       "      <td>1.234217</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>-1.399358</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>-1.250483</td>\n",
       "      <td>1.175099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>7.668096</td>\n",
       "      <td>-2.868917</td>\n",
       "      <td>5.046779</td>\n",
       "      <td>2.300111</td>\n",
       "      <td>-2.759581</td>\n",
       "      <td>4.649038</td>\n",
       "      <td>-1.302922</td>\n",
       "      <td>-0.842877</td>\n",
       "      <td>3.635046</td>\n",
       "      <td>-2.213576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136507</td>\n",
       "      <td>0.110009</td>\n",
       "      <td>0.865617</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.044812</td>\n",
       "      <td>0.100827</td>\n",
       "      <td>0.081222</td>\n",
       "      <td>0.091864</td>\n",
       "      <td>0.069458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>-3.016385</td>\n",
       "      <td>-4.275195</td>\n",
       "      <td>0.433993</td>\n",
       "      <td>-3.314471</td>\n",
       "      <td>2.770625</td>\n",
       "      <td>-2.193447</td>\n",
       "      <td>-3.308840</td>\n",
       "      <td>-1.032386</td>\n",
       "      <td>-0.966145</td>\n",
       "      <td>1.128997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080041</td>\n",
       "      <td>0.038616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140718</td>\n",
       "      <td>0.720374</td>\n",
       "      <td>0.543508</td>\n",
       "      <td>0.112962</td>\n",
       "      <td>0.074878</td>\n",
       "      <td>0.041312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>-2.283719</td>\n",
       "      <td>-1.714166</td>\n",
       "      <td>-1.305149</td>\n",
       "      <td>-1.163707</td>\n",
       "      <td>1.241179</td>\n",
       "      <td>1.242572</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.545328</td>\n",
       "      <td>1.573938</td>\n",
       "      <td>-0.140832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250663</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.058061</td>\n",
       "      <td>0.657860</td>\n",
       "      <td>0.613576</td>\n",
       "      <td>0.419220</td>\n",
       "      <td>0.082663</td>\n",
       "      <td>0.050680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5488 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         5         6         7  \\\n",
       "id                                                                           \n",
       "7218 -2.051437 -0.669757 -0.315596  0.801923  0.463098 -0.606504  0.774105   \n",
       "6333 -2.525180  0.028389 -0.416241 -1.058156  0.897606  1.331595  1.021448   \n",
       "6867  2.291903 -0.143319  2.981271 -0.610320  4.577984 -2.032192  2.292870   \n",
       "7730 -1.399055  4.003945 -0.877522 -1.250140  0.971122 -0.085330 -0.685970   \n",
       "6338  0.134350  1.608424  1.234319 -1.729691 -3.498270  1.538762  2.223016   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "456  -0.835904 -0.338931  0.450743 -0.228883  0.557945  2.058186  0.317780   \n",
       "4084  0.767188  1.727126  3.389711  1.114812  1.234217  0.578990 -1.399358   \n",
       "5117  7.668096 -2.868917  5.046779  2.300111 -2.759581  4.649038 -1.302922   \n",
       "3334 -3.016385 -4.275195  0.433993 -3.314471  2.770625 -2.193447 -3.308840   \n",
       "2403 -2.283719 -1.714166 -1.305149 -1.163707  1.241179  1.242572  0.615113   \n",
       "\n",
       "             8         9        10  ...     ch_37     ch_38     ch_63  \\\n",
       "id                                  ...                                 \n",
       "7218  0.931920 -0.480700  2.462802  ...  0.256266  0.538795  0.000000   \n",
       "6333  0.557510  1.062243  0.484856  ...  0.398772  0.132388  0.000000   \n",
       "6867  0.467942  0.524660 -0.777841  ...  0.217631  0.269911  0.233436   \n",
       "7730 -0.353868  0.193804 -0.917611  ...  0.084188  0.047046  0.000000   \n",
       "6338  0.389273  0.170613  5.642231  ...  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "456   0.399139 -1.141895  2.118095  ...  0.441300  0.494900  0.378768   \n",
       "4084 -0.018394 -1.250483  1.175099  ...  0.000000  0.000000  0.181204   \n",
       "5117 -0.842877  3.635046 -2.213576  ...  0.136507  0.110009  0.865617   \n",
       "3334 -1.032386 -0.966145  1.128997  ...  0.080041  0.038616  0.000000   \n",
       "2403  0.545328  1.573938 -0.140832  ...  0.250663  0.031460  0.000000   \n",
       "\n",
       "         ch_64     ch_65     ch_66     ch_67     ch_68     ch_69     ch_70  \n",
       "id                                                                          \n",
       "7218  0.000000  0.004936  0.315108  0.278908  0.401495  0.321690  0.440164  \n",
       "6333  0.000000  0.000000  0.081961  0.297379  0.517149  0.529480  0.393846  \n",
       "6867  0.001039  0.269109  0.215080  0.098708  0.087279  0.121567  0.217158  \n",
       "7730  0.000000  0.474292  0.781341  0.108681  0.192038  0.305995  0.073333  \n",
       "6338  0.000000  0.000000  0.000000  0.007494  0.211330  0.172361  0.194843  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "456   0.000000  0.000000  0.016593  0.178372  0.101630  0.273780  0.250273  \n",
       "4084  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5117  0.000560  0.002241  0.044812  0.100827  0.081222  0.091864  0.069458  \n",
       "3334  0.000000  0.140718  0.720374  0.543508  0.112962  0.074878  0.041312  \n",
       "2403  0.000984  0.058061  0.657860  0.613576  0.419220  0.082663  0.050680  \n",
       "\n",
       "[5488 rows x 300 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_canny_color.iloc[:, col]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d9ead10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC(kernel=\"linear\", C=1.0)\n",
    "SVM.fit(train_data, train_metadata[\"ClassId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f263b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_test = extract_canny(\"test\")\n",
    "test_color_hist = pd.read_csv(\"Data/test/Features/color_histogram.csv\")\n",
    "test_color_hist.index = test_metadata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e51d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>ch_86</th>\n",
       "      <th>ch_87</th>\n",
       "      <th>ch_88</th>\n",
       "      <th>ch_89</th>\n",
       "      <th>ch_90</th>\n",
       "      <th>ch_91</th>\n",
       "      <th>ch_92</th>\n",
       "      <th>ch_93</th>\n",
       "      <th>ch_94</th>\n",
       "      <th>ch_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.972194</td>\n",
       "      <td>0.372827</td>\n",
       "      <td>-1.312706</td>\n",
       "      <td>0.921197</td>\n",
       "      <td>-0.936266</td>\n",
       "      <td>-1.190727</td>\n",
       "      <td>1.052612</td>\n",
       "      <td>1.272004</td>\n",
       "      <td>-1.311363</td>\n",
       "      <td>3.494884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>0.076151</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.125882</td>\n",
       "      <td>0.093246</td>\n",
       "      <td>0.087806</td>\n",
       "      <td>0.076928</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>0.840764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.428937</td>\n",
       "      <td>-2.584756</td>\n",
       "      <td>1.242029</td>\n",
       "      <td>2.571882</td>\n",
       "      <td>0.195155</td>\n",
       "      <td>0.276150</td>\n",
       "      <td>-0.090557</td>\n",
       "      <td>-0.779253</td>\n",
       "      <td>2.988510</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.410320</td>\n",
       "      <td>-3.148561</td>\n",
       "      <td>-0.090595</td>\n",
       "      <td>-2.218615</td>\n",
       "      <td>-1.177240</td>\n",
       "      <td>-0.457714</td>\n",
       "      <td>-1.201756</td>\n",
       "      <td>1.831517</td>\n",
       "      <td>-0.610035</td>\n",
       "      <td>0.224229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.074435</td>\n",
       "      <td>1.948776</td>\n",
       "      <td>-0.925813</td>\n",
       "      <td>1.062414</td>\n",
       "      <td>-1.761376</td>\n",
       "      <td>-2.204464</td>\n",
       "      <td>-0.819742</td>\n",
       "      <td>-0.378842</td>\n",
       "      <td>-1.077743</td>\n",
       "      <td>-2.029878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.731861</td>\n",
       "      <td>4.398859</td>\n",
       "      <td>0.981835</td>\n",
       "      <td>-1.039885</td>\n",
       "      <td>-0.704322</td>\n",
       "      <td>1.110292</td>\n",
       "      <td>2.530677</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>-0.466632</td>\n",
       "      <td>-1.416666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>-0.224179</td>\n",
       "      <td>1.002199</td>\n",
       "      <td>-0.207040</td>\n",
       "      <td>0.937442</td>\n",
       "      <td>-1.572850</td>\n",
       "      <td>0.669617</td>\n",
       "      <td>-0.862222</td>\n",
       "      <td>-0.959062</td>\n",
       "      <td>0.469508</td>\n",
       "      <td>-1.186071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>-1.112046</td>\n",
       "      <td>1.533942</td>\n",
       "      <td>-1.101301</td>\n",
       "      <td>-3.926783</td>\n",
       "      <td>3.161074</td>\n",
       "      <td>2.479483</td>\n",
       "      <td>-1.725642</td>\n",
       "      <td>-0.946823</td>\n",
       "      <td>0.780640</td>\n",
       "      <td>-2.549285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>1.800065</td>\n",
       "      <td>0.597188</td>\n",
       "      <td>-2.726380</td>\n",
       "      <td>1.045198</td>\n",
       "      <td>-2.418544</td>\n",
       "      <td>0.566243</td>\n",
       "      <td>-1.156263</td>\n",
       "      <td>-1.097498</td>\n",
       "      <td>0.850812</td>\n",
       "      <td>1.286888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066123</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.044082</td>\n",
       "      <td>0.040074</td>\n",
       "      <td>0.096179</td>\n",
       "      <td>0.100186</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.052097</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>0.043080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2.402601</td>\n",
       "      <td>-3.318600</td>\n",
       "      <td>0.953507</td>\n",
       "      <td>0.732682</td>\n",
       "      <td>-1.205913</td>\n",
       "      <td>4.622538</td>\n",
       "      <td>-0.337615</td>\n",
       "      <td>-1.107822</td>\n",
       "      <td>-0.101137</td>\n",
       "      <td>-0.329561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040461</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.095909</td>\n",
       "      <td>0.039712</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.025476</td>\n",
       "      <td>0.182076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>-3.850801</td>\n",
       "      <td>-1.488356</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>0.794651</td>\n",
       "      <td>-0.116687</td>\n",
       "      <td>0.176844</td>\n",
       "      <td>-0.774953</td>\n",
       "      <td>-0.110350</td>\n",
       "      <td>-0.212451</td>\n",
       "      <td>0.466606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051149</td>\n",
       "      <td>0.041233</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2353 rows × 1096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     3.972194  0.372827 -1.312706  0.921197 -0.936266 -1.190727  1.052612   \n",
       "1     4.428937 -2.584756  1.242029  2.571882  0.195155  0.276150 -0.090557   \n",
       "2     3.410320 -3.148561 -0.090595 -2.218615 -1.177240 -0.457714 -1.201756   \n",
       "3    -3.074435  1.948776 -0.925813  1.062414 -1.761376 -2.204464 -0.819742   \n",
       "4    -0.731861  4.398859  0.981835 -1.039885 -0.704322  1.110292  2.530677   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2348 -0.224179  1.002199 -0.207040  0.937442 -1.572850  0.669617 -0.862222   \n",
       "2349 -1.112046  1.533942 -1.101301 -3.926783  3.161074  2.479483 -1.725642   \n",
       "2350  1.800065  0.597188 -2.726380  1.045198 -2.418544  0.566243 -1.156263   \n",
       "2351  2.402601 -3.318600  0.953507  0.732682 -1.205913  4.622538 -0.337615   \n",
       "2352 -3.850801 -1.488356  0.083159  0.794651 -0.116687  0.176844 -0.774953   \n",
       "\n",
       "             7         8         9  ...     ch_86     ch_87     ch_88  \\\n",
       "0     1.272004 -1.311363  3.494884  ...  0.059833  0.076151  0.062164   \n",
       "1    -0.779253  2.988510  0.004688  ...  0.000000  0.000000  0.000000   \n",
       "2     1.831517 -0.610035  0.224229  ...  0.000000  0.000000  0.000000   \n",
       "3    -0.378842 -1.077743 -2.029878  ...  0.000000  0.000000  0.000000   \n",
       "4     0.198082 -0.466632 -1.416666  ...  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2348 -0.959062  0.469508 -1.186071  ...  0.005119  0.001463  0.000000   \n",
       "2349 -0.946823  0.780640 -2.549285  ...  0.000000  0.000000  0.000000   \n",
       "2350 -1.097498  0.850812  1.286888  ...  0.066123  0.059110  0.044082   \n",
       "2351 -1.107822 -0.101137 -0.329561  ...  0.040461  0.093661  0.095909   \n",
       "2352 -0.110350 -0.212451  0.466606  ...  0.051149  0.041233  0.015658   \n",
       "\n",
       "         ch_89     ch_90     ch_91     ch_92     ch_93     ch_94     ch_95  \n",
       "0     0.090137  0.125882  0.093246  0.087806  0.076928  0.096354  0.840764  \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2348  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2349  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2350  0.040074  0.096179  0.100186  0.042078  0.052097  0.029054  0.043080  \n",
       "2351  0.039712  0.016484  0.009741  0.004496  0.008242  0.025476  0.182076  \n",
       "2352  0.000000  0.000000  0.000000  0.033404  0.000000  0.000000  0.100211  \n",
       "\n",
       "[2353 rows x 1096 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canny_test_pca = apply_pca(canny_test)\n",
    "test_canny_color = pd.concat([canny_test_pca, test_color_hist], axis=1)\n",
    "test_canny_color.columns = test_canny_color.columns.astype(str)\n",
    "test_canny_color = test_canny_color.drop(columns=[\"image_path\"])\n",
    "test_canny_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "77ce0cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 16, 21, ...,  3,  4, 11])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_canny_color.iloc[:, col]\n",
    "predictions = SVM.predict(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "74f64999",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'id': test_index, 'ClassId': predictions})\n",
    "result.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
